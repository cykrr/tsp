{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zQP708EbgE6j",
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "Se compara el desempeño entre los siguientes modelos/solvers:\n",
    "\n",
    "* Modelo base\n",
    "* Modelo bloque Transformer\n",
    "* Modelo bloque Transformer * 6\n",
    "* Modelo con encoding posicional\n",
    "* Greedy\n",
    "* OR-Tools\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Descarga de librerías"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uXy_uobPgEt1",
    "outputId": "9d951eb9-25de-4968-effd-168da4625519"
   },
   "outputs": [],
   "source": [
    "# Descarga de librerías\n",
    "\n",
    "# Linux only, doesn't work on windows\n",
    "# ! python -c \"import ortools\" 2>/dev/null  && echo \"OR-Tools is already installed\" || pip install ortools -q\n",
    "# ! [[ ! -d eda ]]  && echo \"Downloading eda repo\" && curl -L  https://github.com/rilianx/eda/archive/refs/heads/main.tar.gz | tar xzvf - && mv eda-main eda\n",
    "# import torch\n",
    "# !pip install tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! curl -LO https://github.com/rilianx/eda/archive/refs/heads/main.tar.gz\n",
    "# ! 7z x main.tar.gz\n",
    "# ! 7z x main.tar\n",
    "# ! move eda-main eda\n",
    "# ! del main.tar.gz\n",
    "# ! del main.tar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## state2vecSeq\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "41HRC0zLhJ9P",
    "outputId": "623e161d-65ab-43b9-b402-c75ea81c6dd7"
   },
   "outputs": [],
   "source": [
    "# Generación de datos\n",
    "\n",
    "\n",
    "from copy import deepcopy\n",
    "import random\n",
    "import math\n",
    "\n",
    "import numpy as np\n",
    "from torch.nn.functional import one_hot\n",
    "from eda.TSP import TSP_Instance, TSP_Environment, TSP_State\n",
    "from eda.solveTSP_v2 import solve\n",
    "env = TSP_Environment\n",
    "\n",
    "def distance(punto1, punto2):\n",
    "    return math.sqrt((punto1[0] - punto2[0])**2 + (punto1[1] - punto2[1])**2)\n",
    "\n",
    "# función para transformar un estado tsp en una secuencia de vectores\n",
    "# para el modelo basado en capas de atención\n",
    "def state2vecSeq(self):\n",
    "    # creamos dos diccionarios para mantenre un mapeo de los\n",
    "    # movimientos con los índices de la secuencia del modelo de aprendizaje\n",
    "\n",
    "    city_locations = self.inst_info.city_locations\n",
    "\n",
    "    idx2move = dict()\n",
    "    move2idx = dict()\n",
    "    origin = city_locations[self.visited[-1]]\n",
    "    destination = city_locations[self.visited[0]]\n",
    "\n",
    "    origin_dist = 0.0\n",
    "    dest_dist = distance(origin, destination)\n",
    "\n",
    "    seq = [list(origin) + [1,0] + [origin_dist, dest_dist], # Última ciudad visitada (origen)\n",
    "           list(destination) + [0, 1] + [dest_dist, 0.0]]  # Ciudad final\n",
    "\n",
    "    idx2move[0] = None\n",
    "    idx2move[1] = (\"constructive\", self.visited[0])\n",
    "    move2idx[self.visited[0]] = 1\n",
    "\n",
    "    idx = 2\n",
    "    for i in self.not_visited:\n",
    "        point = list(city_locations[i])\n",
    "        origin_dist = distance( point, origin)\n",
    "        dest_dist = distance( point, destination)\n",
    "        city_vector = point + [0, 0] + [origin_dist, dest_dist] # Otras ciudades\n",
    "\n",
    "        seq.append(city_vector)\n",
    "        idx2move[idx] = (\"constructive\", i)\n",
    "        move2idx[i] = idx\n",
    "        idx += 1\n",
    "\n",
    "    return seq, idx2move, move2idx\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Meta clase para definir modelos y ciclo de entrenamiento\n",
    "\n",
    "Se definen hiperparámetros de los modelos a evaluar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vf7E9wqajd6_",
    "outputId": "de948908-2df5-4c1c-e8ec-090b370758e9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.Model at 0x26209d7a5d0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Todos los modelos serán entrenados con el mismo dataset\n",
    "# X: [20000, 11, 6], Y: [20000, 11]\n",
    "# donde X: (nb_sample, max_cities + 1, param_count), Y: (nb_sample, max_cities+1)\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "class Model:\n",
    "    # El modelo se genera en el constructor y se guarda en self.model\n",
    "    def __init__(self, \n",
    "         input_dim = 6,\n",
    "         num_heads = 10,\n",
    "         head_dim = 64,\n",
    "         city_count = 50,\n",
    "                 \n",
    "         batch_size = 512,\n",
    "         train_split = 0.5,\n",
    "         nb_samples = 20000,\n",
    "         epochs = 10):\n",
    "\n",
    "        self.city_count = city_count # Número de ciudades a evaluar\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "        ## Parámetros modelo\n",
    "        self.input_dim = input_dim  # Dimensión de la entrada\n",
    "        self.num_heads = num_heads  # Número de cabezas en la atención multi-cabeza\n",
    "        self.head_dim = head_dim  # Dimensión de cada cabeza\n",
    "        ## Parámetros entrenamiento\n",
    "        self.batch_size = batch_size\n",
    "        self.train_split = train_split\n",
    "        self.nb_samples = nb_samples\n",
    "        self.epochs = 10\n",
    "\n",
    "        \n",
    "        self.model = None\n",
    "    \n",
    "    \n",
    "    def load_model(self):\n",
    "        raise NotImplementedError(\"La función 'load_model' debe ser declarada\")\n",
    "    def unload_model(self):\n",
    "        raise NotImplementedError(\"La función 'unload_model' debe ser implementada\");\n",
    "\n",
    "    def train(self, x, y):\n",
    "        raise NotImplementedError(\"La función 'train' debe ser declarada\")\n",
    "      \n",
    "\n",
    "    def generate_data(self, use_progress_bar=False):\n",
    "        X = []  # Lista para almacenar las secuencias de entrada\n",
    "        Y = []  # Lista para almacenar las etiquetas objetivo (las siguientes ciudades a visitar)\n",
    "        seq_len = self.city_count + 1  # Longitud de la secuencia, ajustada para incluir una ciudad extra\n",
    "        \n",
    "        # If the flag is set, initialize the progress bar\n",
    "        pbar = tqdm(total=self.nb_samples, desc=\"Generating data\", unit=\"sample\", position=0, leave=True) if use_progress_bar else None\n",
    "        \n",
    "        # Bucle para generar datos hasta alcanzar el número deseado de muestras\n",
    "        while True:\n",
    "            # 1. Generamos instancia aleatoria\n",
    "            n_cities = self.city_count\n",
    "            dim = 2  # Dimensión para las coordenadas de la ciudad (2D: x, y)\n",
    "            city_points = np.random.rand(n_cities, dim)  # Generar puntos aleatorios para las ciudades\n",
    "            inst_info = TSP_Instance(city_points)\n",
    "    \n",
    "            # 2. Resolvemos TSP usando algoritmo tradicional\n",
    "            solution = solve(city_points)  # Resolver el TSP y obtener un estado final\n",
    "    \n",
    "            # 3. Iteramos sobre los movimientos de la solución final para generar varias muestras:\n",
    "            # estado (X) -> movimiento (Y)\n",
    "            current_state = TSP_State(inst_info)\n",
    "            env.state_transition(current_state, (\"constructive\", solution.visited[0]))\n",
    "            samples_per_sol = self.city_count - 1  # Número máximo de muestras por solución\n",
    "            \n",
    "            for move in [(\"constructive\", city) for city in solution.visited[1:]]:\n",
    "                seq, _, move2idx = state2vecSeq(current_state)  # Convertir el estado actual a secuencia vectorizada\n",
    "    \n",
    "                X.append(torch.tensor(seq))  # Añadir la secuencia a X\n",
    "                Y.append(one_hot(torch.tensor(move2idx[move[1]]), num_classes=seq_len))\n",
    "                #Y.append(to_categorical(move2idx[move[1]], num_classes=seq_len))  # Añadir el movimiento como categoría a Y\n",
    "    \n",
    "                env.state_transition(current_state, move)  # Hacer la transición al siguiente estado\n",
    "    \n",
    "                # Actualizar el progreso de la barra si se está usando\n",
    "                if use_progress_bar:\n",
    "                    pbar.update(1)\n",
    "    \n",
    "                # Condiciones de parada basadas en el número de ciudades visitadas/no visitadas o muestras generadas\n",
    "                if len(current_state.visited) > samples_per_sol or len(X) >= self.nb_samples:\n",
    "                    break\n",
    "    \n",
    "            # Romper el bucle externo si se ha alcanzado el número deseado de muestras\n",
    "            if len(X) >= self.nb_samples:\n",
    "                break\n",
    "        \n",
    "        # Close the progress bar if it was used\n",
    "        if use_progress_bar:\n",
    "            pbar.close()\n",
    "    \n",
    "        X_padded = torch.nn.utils.rnn.pad_sequence(X, batch_first=True)\n",
    "        \n",
    "        return X_padded, torch.stack(Y)\n",
    "\n",
    "\n",
    "Model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "m9yrvnSSnDeT"
   },
   "outputs": [],
   "source": [
    "## Definición base de modelo para usar el mismo entrenamiento en los distintos modelos\n",
    "import pandas as pd\n",
    "import gc\n",
    "class TrainableModel(Model):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # Parámetros del modelo\n",
    "    def unload_model(self):\n",
    "        del model.model\n",
    "        torch.cuda.empty_cache()\n",
    "        gc.collect()\n",
    "\n",
    "    def train(self, xt, yt, xv, yv, num_iter=-1, use_progress_bar=False):\n",
    "        # self.load_model()\n",
    "        # Asumiendo que X_padded y Y_stacked ya están definidos y son tensores de PyTorch\n",
    "        trd = TensorDataset(xt, yt)\n",
    "        ted = TensorDataset(xv, yv)\n",
    "    \n",
    "        # # Dividir el dataset en entrenamiento y prueba\n",
    "        # train_size = int(self.train_split * len(dataset))\n",
    "        # test_size = len(dataset) - train_size\n",
    "        train_dataset, test_dataset = trd, ted\n",
    "    \n",
    "        train_loader = DataLoader(train_dataset, batch_size=self.batch_size, shuffle=True)\n",
    "        test_loader = DataLoader(test_dataset, batch_size=self.batch_size, shuffle=False)\n",
    "    \n",
    "        # Definir el modelo, la función de pérdida y el optimizador\n",
    "        loss_function = torch.nn.CrossEntropyLoss()\n",
    "        optimizer = torch.optim.Adam(self.model.parameters())\n",
    "    \n",
    "        # Initialize the DataFrame to store training results\n",
    "        df = pd.DataFrame(columns=[\"Model Name\", \"cities\", \"iter\", \"Epoch\",\n",
    "                                   \"Training Loss\", \"Training Accuracy\",\n",
    "                                   \"Validation Loss\", \"Validation Accuracy\"])\n",
    "    \n",
    "        # Initialize the progress bar for epochs if required\n",
    "        epoch_range = range(self.epochs)\n",
    "        if use_progress_bar:\n",
    "            epoch_range = tqdm(epoch_range, desc=\"Training Epochs\", unit=\"epoch\", position = 0, leave = True)\n",
    "        \n",
    "        print(\"Entrenando modelo...\")\n",
    "        for epoch in epoch_range:\n",
    "            self.model.train()\n",
    "            train_loss = 0\n",
    "            correct = 0\n",
    "            total = 0\n",
    "            for X_batch, y_batch in train_loader:\n",
    "                optimizer.zero_grad()  # Limpia los gradientes\n",
    "                outputs = self.model(X_batch)  # Obtenemos logits\n",
    "                loss = loss_function(outputs, y_batch.argmax(dim=1))  # Calcular la pérdida\n",
    "                loss.backward()  # Backward pass\n",
    "                optimizer.step()  # Actualizar parámetros\n",
    "                train_loss += loss.item() * X_batch.size(0)\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                total += y_batch.size(0)\n",
    "                correct += (predicted == y_batch.argmax(dim=1)).sum().item()\n",
    "    \n",
    "            train_loss /= len(train_loader.dataset)\n",
    "            train_accuracy = 100 * correct / total\n",
    "    \n",
    "            # Validación\n",
    "            self.model.eval()\n",
    "            validation_loss = 0\n",
    "            correct = 0\n",
    "            total = 0\n",
    "            with torch.no_grad():\n",
    "                for X_batch, y_batch in test_loader:\n",
    "                    outputs = self.model(X_batch)\n",
    "                    loss = loss_function(outputs, y_batch.argmax(dim=1))\n",
    "                    validation_loss += loss.item() * X_batch.size(0)\n",
    "                    _, predicted = torch.max(outputs.data, 1)\n",
    "                    total += y_batch.size(0)\n",
    "                    correct += (predicted == y_batch.argmax(dim=1)).sum().item()\n",
    "    \n",
    "            validation_loss /= len(test_loader.dataset)\n",
    "            validation_accuracy = 100 * correct / total\n",
    "    \n",
    "            # Log results to DataFrame\n",
    "            df = pd.concat([df, pd.DataFrame([{\n",
    "                \"Model Name\": type(self).__name__,\n",
    "                \"cities\": self.city_count,\n",
    "                \"iter\": num_iter,\n",
    "                \"Epoch\": epoch + 1,\n",
    "                \"Training Loss\": train_loss,\n",
    "                \"Training Accuracy\": train_accuracy,\n",
    "                \"Validation Loss\": validation_loss,\n",
    "                \"Validation Accuracy\": validation_accuracy\n",
    "            }])], ignore_index=True)\n",
    "    \n",
    "            # print(f'Epoch {epoch+1}, Train Loss: {train_loss:.4f}, Train Accuracy: {train_accuracy:.2f}%')\n",
    "            # print(f'Epoch {epoch+1}, Val Loss: {validation_loss:.4f}, Val Accuracy: {validation_accuracy:.2f}%')\n",
    "    \n",
    "        # If tqdm was used, close the progress bar\n",
    "        if use_progress_bar:\n",
    "            epoch_range.close()\n",
    "    \n",
    "        # self.unload_model()\n",
    "        return df;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "29HSyNmfgu8g"
   },
   "outputs": [],
   "source": [
    "## Modelo base\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import DataLoader, TensorDataset, random_split\n",
    "\n",
    "class BaseModel(TrainableModel):\n",
    "\n",
    "    \n",
    "    def load_model(self):\n",
    "        self.model = BaseModel.CustomModel(self.input_dim, self.num_heads, self.head_dim)\n",
    "        \n",
    "    class CustomModel(nn.Module):\n",
    "        def __init__(self, input_dim, num_heads, head_dim, dropout_rate=0.2):\n",
    "            super(BaseModel.CustomModel, self).__init__()\n",
    "            #self.seq_length = seq_length  # Asumiendo una longitud fija de secuencia para simplificar\n",
    "            self.num_heads = num_heads\n",
    "            self.head_dim = head_dim\n",
    "\n",
    "            # Proyección de entrada\n",
    "            self.input_projection = nn.Linear(input_dim, num_heads * head_dim)\n",
    "\n",
    "            # Capa de atención multi-cabeza\n",
    "            self.multihead_attention = nn.MultiheadAttention(embed_dim=num_heads * head_dim,\n",
    "                                                            num_heads=num_heads,\n",
    "                                                            dropout=dropout_rate)\n",
    "\n",
    "            # Capas lineales individuales para cada posición de la secuencia\n",
    "            # Esto es un cambio respecto al código original para aplicar una capa lineal por posición de salida\n",
    "            self.positionwise_linear = nn.Linear(num_heads * head_dim, 1)\n",
    "\n",
    "            # Capa de salida final, después de un flatten, para aplicar Softmax\n",
    "            # Nota: Softmax se aplica después del flatten, por lo tanto no se define aquí como una capa pero sí en el forward\n",
    "\n",
    "        def generate_attention_mask(self, x, padding_value=0):\n",
    "            # Identificar posiciones de padding en x\n",
    "            mask = (x.sum(dim=-1) == padding_value)  # Asumiendo que el padding se puede identificar sumando los valores de la característica y comparando con 0\n",
    "            mask = mask.to(dtype=torch.bool)  # Convierte a bool para usar como máscara\n",
    "            # PyTorch espera una máscara con True y False donde True indica donde aplicar la máscara\n",
    "            return mask\n",
    "\n",
    "\n",
    "        def forward(self, x, seq_lengths=10, return_probabilities=False):\n",
    "            # x: [batch_size, seq_length, input_dim]\n",
    "            x = x.float()\n",
    "\n",
    "            max_len = x.shape[1]\n",
    "\n",
    "            # Generar máscara de atención basada en las longitudes de las secuencias\n",
    "            attn_mask = None\n",
    "\n",
    "            # Aplicar proyección de entrada\n",
    "            x_proj = self.input_projection(x)\n",
    "            x_proj = x_proj.permute(1, 0, 2)  # Reordenar para multihead_attention: [seq_length, batch_size, num_heads*head_dim]\n",
    "\n",
    "\n",
    "            # Aplicar atención multi-cabeza\n",
    "            attn_output, _ = self.multihead_attention(x_proj, x_proj, x_proj, attn_mask=attn_mask)\n",
    "            attn_output = attn_output.permute(1, 0, 2)  # Reordenar de vuelta: [batch_size, seq_length, num_heads*head_dim]\n",
    "\n",
    "            # Aplicar la capa lineal posición por posición\n",
    "            # Usamos una capa lineal que se aplica a cada vector de salida de la atención de forma independiente\n",
    "            positionwise_output = self.positionwise_linear(attn_output)\n",
    "\n",
    "            # Flatten\n",
    "            flat_output = positionwise_output.view(positionwise_output.size(0), -1)  # [batch_size, seq_length]\n",
    "\n",
    "            # Softmax\n",
    "            if return_probabilities:\n",
    "                output = F.softmax(flat_output, dim=-1)\n",
    "                return output\n",
    "            else: #return logits\n",
    "                return flat_output\n",
    "\n",
    "\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "    def load_model(self):\n",
    "        self.model = BaseModel.CustomModel(input_dim=self.input_dim, num_heads=self.num_heads, head_dim=self.head_dim)\n",
    "        self.model.to(self.device)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "cgkPpHf5mihM"
   },
   "outputs": [],
   "source": [
    "class TransformerBlockModel(TrainableModel):\n",
    "\n",
    "  class CustomModel(nn.Module):\n",
    "    class TransformerBlock(nn.Module):\n",
    "        def __init__(self, input_dim, num_heads, head_dim, ff_dim, dropout_rate=0.2):\n",
    "            super(TransformerBlockModel.CustomModel.TransformerBlock, self).__init__()\n",
    "            self.attention = nn.MultiheadAttention(embed_dim=num_heads * head_dim, num_heads=num_heads, dropout=dropout_rate)\n",
    "            self.norm1 = nn.LayerNorm(input_dim)  # LayerNorm based on input_dim\n",
    "            self.ff = nn.Sequential(\n",
    "                nn.Linear(input_dim, ff_dim),\n",
    "                nn.ReLU(),\n",
    "            )\n",
    "            self.norm2 = nn.LayerNorm(input_dim)  # LayerNorm based on input_dim\n",
    "            self.dropout = nn.Dropout(dropout_rate)\n",
    "    \n",
    "        def forward(self, x):\n",
    "            # Attention block\n",
    "            attn_output, _ = self.attention(x, x, x)  # x: (seq_len, batch_size, input_dim)\n",
    "            x = self.norm1(x + self.dropout(attn_output))  # Residual + Norm\n",
    "            \n",
    "            # Feed-forward block\n",
    "            ff_output = self.ff(x)\n",
    "            x = self.norm2(x + self.dropout(ff_output))  # Residual + Norm\n",
    "        \n",
    "            return x\n",
    "\n",
    "    def __init__(self, input_dim, num_heads, head_dim, dropout_rate=0.2):\n",
    "        super(TransformerBlockModel.CustomModel, self).__init__()\n",
    "        #self.seq_length = seq_length  # Asumiendo una longitud fija de secuencia para simplificar\n",
    "        self.num_heads = num_heads\n",
    "        self.head_dim = head_dim\n",
    "        \n",
    "        # Proyección de entrada\n",
    "        self.input_projection = nn.Linear(input_dim, num_heads * head_dim)\n",
    "        \n",
    "        self.attention_blocks = nn.ModuleList([\n",
    "          TransformerBlockModel.CustomModel.TransformerBlock(input_dim=num_heads * head_dim,\n",
    "                                        num_heads=num_heads,\n",
    "                                        head_dim=head_dim,\n",
    "                                        ff_dim=num_heads * head_dim,\n",
    "                                        dropout_rate=dropout_rate)\n",
    "        ])\n",
    "    \n",
    "        # Capas lineales individuales para cada posición de la secuencia\n",
    "        # Esto es un cambio respecto al código original para aplicar una capa lineal por posición de salida\n",
    "        self.positionwise_linear = nn.Linear(num_heads * head_dim, 1)\n",
    "        \n",
    "        # Capa de salida final, después de un flatten, para aplicar Softmax\n",
    "        # Nota: Softmax se aplica después del flatten, por lo tanto no se define aquí como una capa pero sí en el forward\n",
    "\n",
    "    def generate_attention_mask(self, x, padding_value=0):\n",
    "      # Identificar posiciones de padding en x\n",
    "      mask = (x.sum(dim=-1) == padding_value)  # Asumiendo que el padding se puede identificar sumando los valores de la característica y comparando con 0\n",
    "      mask = mask.to(dtype=torch.bool)  # Convierte a bool para usar como máscara\n",
    "      # PyTorch espera una máscara con True y False donde True indica donde aplicar la máscara\n",
    "      return mask\n",
    "    \n",
    "    \n",
    "    def forward(self, x, seq_lengths=10, return_probabilities=False):\n",
    "      # x: [batch_size, seq_length, input_dim]\n",
    "      x = x.float()\n",
    "    \n",
    "      max_len = x.shape[1]\n",
    "    \n",
    "      # Generar máscara de atención basada en las longitudes de las secuencias\n",
    "      attn_mask = None\n",
    "    \n",
    "      # Aplicar proyección de entrada\n",
    "      x_proj = self.input_projection(x)\n",
    "      attn_output = x_proj\n",
    "      x_proj = x_proj.permute(1, 0, 2)  # Reordenar para multihead_attention: [seq_length, batch_size, num_heads*head_dim]\n",
    "    \n",
    "    \n",
    "      # Aplicar atención multi-cabeza\n",
    "      attn_output = self.attention_blocks[0](x_proj)\n",
    "      attn_output = attn_output.permute(1, 0, 2)  # Reordenar de vuelta: [batch_size, seq_length, num_heads*head_dim]\n",
    "    \n",
    "      # Aplicar la capa lineal posición por posición\n",
    "      # Usamos una capa lineal que se aplica a cada vector de salida de la atención de forma independiente\n",
    "      positionwise_output = self.positionwise_linear(attn_output)\n",
    "    \n",
    "      # Flatten\n",
    "      flat_output = positionwise_output.view(positionwise_output.size(0), -1)  # [batch_size, seq_length]\n",
    "    \n",
    "      # Softmax\n",
    "      if return_probabilities:\n",
    "        output = F.softmax(flat_output, dim=-1)\n",
    "        return output\n",
    "      else: #return logits\n",
    "        return flat_output\n",
    "\n",
    "  def load_model(self):\n",
    "    self.model = TransformerBlockModel.CustomModel(input_dim=self.input_dim, num_heads=self.num_heads, head_dim=self.head_dim)\n",
    "    self.model = self.model.to(self.device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "6ekvlK8Qn3HK"
   },
   "outputs": [],
   "source": [
    "## Transformer Block Multicapa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "zRQEnT8Aop_R"
   },
   "outputs": [],
   "source": [
    "class MultilayerTransformerBlockModel(TrainableModel):\n",
    "  class CustomModel(TransformerBlockModel.CustomModel):\n",
    "      def __init__(self, input_dim, num_heads, head_dim, dropout_rate=0.2):\n",
    "          super().__init__(input_dim, num_heads, head_dim, dropout_rate)\n",
    "          self.attention_blocks = nn.ModuleList([TransformerBlockModel.CustomModel.TransformerBlock(input_dim=num_heads * head_dim,\n",
    "                                            num_heads=num_heads,\n",
    "                                            head_dim=head_dim,\n",
    "                                            ff_dim=num_heads * head_dim,\n",
    "                                            dropout_rate=dropout_rate)]*6)\n",
    "      def forward(self, x, seq_lengths=10, return_probabilities=False):\n",
    "          # x: [batch_size, seq_length, input_dim]\n",
    "          x = x.float()\n",
    "\n",
    "          max_len = x.shape[1]\n",
    "\n",
    "          # Generar máscara de atención basada en las longitudes de las secuencias\n",
    "          attn_mask = None\n",
    "\n",
    "          # Aplicar proyección de entrada\n",
    "          x_proj = self.input_projection(x)\n",
    "          attn_output = x_proj\n",
    "          x_proj = x_proj.permute(1, 0, 2)  # Reordenar para multihead_attention: [seq_length, batch_size, num_heads*head_dim]\n",
    "\n",
    "\n",
    "          # Aplicar atención multi-cabeza\n",
    "          for i in range(len(self.attention_blocks)):\n",
    "              attn_output = self.attention_blocks[i](x_proj)\n",
    "          \n",
    "          attn_output = attn_output.permute(1, 0, 2)  # Reordenar de vuelta: [batch_size, seq_length, num_heads*head_dim]\n",
    "\n",
    "          # Aplicar la capa lineal posición por posición\n",
    "          # Usamos una capa lineal que se aplica a cada vector de salida de la atención de forma independiente\n",
    "          positionwise_output = self.positionwise_linear(attn_output)\n",
    "\n",
    "          # Flatten\n",
    "          flat_output = positionwise_output.view(positionwise_output.size(0), -1)  # [batch_size, seq_length]\n",
    "\n",
    "          # Softmax\n",
    "          if return_probabilities:\n",
    "            output = F.softmax(flat_output, dim=-1)\n",
    "            return output\n",
    "          else: #return logits\n",
    "            return flat_output\n",
    "  def __init__(self):\n",
    "    super().__init__()\n",
    "  def load_model(self):\n",
    "    self.model = self.CustomModel(input_dim=self.input_dim, num_heads=self.num_heads, head_dim=self.head_dim)\n",
    "    self.model = self.model.to(self.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 89
    },
    "id": "RIN0IV1Fo61m",
    "outputId": "2cb76ba1-415e-495d-d8f3-ef159cc40637"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WJBJ6roXAQ_C",
    "outputId": "3e0512cf-3f88-40ea-dbf7-c936ecdb6cca"
   },
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# df = pd.DataFrame(columns=[\"Model Name\", \"cities\", \"iter\", \"Epoch\", \"Training Loss\", \"Training Accuracy\", \"Validation Loss\", \"Validation Accuracy\"])\n",
    "# df\n",
    "\n",
    "# dfb = pd.DataFrame(columns=[\"Model Name\", \"cities\", \"iter\", \"avg path cost\"])\n",
    "\n",
    "# import gc\n",
    "# models = [BaseModel(), TransformerBlockModel(), MultilayerTransformerBlockModel()]\n",
    "# # for city_count in [10, 50, 100, 500]:\n",
    "# num_iters=10\n",
    "# eval_count = 50\n",
    "# # for city_count in [50]:\n",
    "\n",
    "# from eda.TSP import TSP_Instance, TSP_Environment, TSP_State, evalConstructiveActions, plot_tour\n",
    "# from eda.agents import SingleAgentSolver, GreedyAgent\n",
    "# import numpy as np\n",
    "\n",
    "\n",
    "# class ModelEvalActions():\n",
    "#   def __init__(self, model):\n",
    "#     self.model=model\n",
    "\n",
    "#   # permite evaluar acctiones de varios estados a la vez\n",
    "#   # para optimizar los cáluclos del modelo\n",
    "#   def __call__(self, states, env):\n",
    "#     single_state = False\n",
    "#     if not isinstance(states, list):\n",
    "#       single_state=True\n",
    "#       states = [states]\n",
    "\n",
    "#     evals = [list() for _ in states]\n",
    "#     vecSeqs=[]; move2idx =[]\n",
    "\n",
    "#     for state in states:\n",
    "#       vecSeq, _, mov2idx = state.state2vecSeq()\n",
    "#       vecSeqs.append(vecSeq)\n",
    "#       move2idx.append(mov2idx)\n",
    "#     device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "#     predictions = self.model(torch.tensor(vecSeqs).to(device), return_probabilities=True)\n",
    "\n",
    "#     for k in range(len(states)):\n",
    "#       state = states[k]\n",
    "#       for action in env.gen_actions(state, \"constructive\"):\n",
    "#           idx = move2idx[k][action[1]] #mapping from move to output index (model)\n",
    "#           evals[k].append((action,predictions[k][idx]))\n",
    "\n",
    "#     if single_state: return evals[0]\n",
    "#     else: return evals\n",
    "\n",
    "# for iter in range(num_iters):\n",
    "#     X = None\n",
    "#     Y = None\n",
    "#     for model in models:\n",
    "#         if X == None and Y == None:\n",
    "#             print(f\"Generando datos iteración i={iter}\")\n",
    "#             X, Y = model.generate_data(use_progress_bar=True)\n",
    "#             X = X.to(model.device)\n",
    "#             Y = Y.to(model.device)\n",
    "        \n",
    "#         name = type(model).__name__\n",
    "#         print(\"Entrenando\", name, \"con n=\", model.city_count)\n",
    "#         trained_model_df = model.train(X, Y, num_iter=iter, use_progress_bar=True)\n",
    "#         pd.concat([df, trained_model_df])\n",
    "#         # Evaluación post entrenamiento\n",
    "#         print(\"Evaluando modelo: Generando 20 instancias\")\n",
    "#         instances = [\n",
    "#             TSP_Instance(np.random.rand(model.city_count, 2)) for _ in tqdm(\n",
    "#                 range(eval_count), desc=\"Instancias\", unit=\"instance\", position=0, leave=True)\n",
    "#         ]\n",
    "#         greedy = SingleAgentSolver (env,GreedyAgent(ModelEvalActions(model.model)))\n",
    "#         solutions = []\n",
    "#         for instance in tqdm(instances, desc=\"Solving Instances\", unit=\"instance\", position=0, leave=True):\n",
    "#             solution, *_ = greedy.solve(TSP_State(instance, visited=[0]))\n",
    "#             solutions.append(solution.cost)\n",
    "#         model.unload_model()\n",
    "\n",
    "#         solutions_prom = sum(solutions) / len(solutions)\n",
    "#         dfb = pd.concat([dfb, pd.DataFrame([{\n",
    "#             \"Model Name\": type(model).__name__,\n",
    "#             \"iter\": iter,\n",
    "#             \"cities\": model.city_count,\n",
    "#             \"avg path cost\": solutions_prom\n",
    "#         }])])\n",
    "        \n",
    "#     del X\n",
    "#     del Y\n",
    "#     X = None\n",
    "#     Y = None\n",
    "\n",
    "\n",
    "# df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "hZDgyCWJGWrY"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m df\u001b[38;5;241m.\u001b[39mto_csv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mout2.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "df.to_csv(\"out2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfb.groupby([\"Model Name\", \"cities\"]).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m df\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_name</th>\n",
       "      <th>fold</th>\n",
       "      <th>epoch</th>\n",
       "      <th>tr_loss</th>\n",
       "      <th>tr_acc</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>val_acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [model_name, fold, epoch, tr_loss, tr_acc, val_loss, val_acc]\n",
       "Index: []"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.DataFrame(columns=[\"model_name\", \"fold\", \"epoch\", \"tr_loss\", \"tr_acc\", \"val_loss\", \"val_acc\"])\n",
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_df = pd.DataFrame(columns=[\"model_name\", \"fold\", \"cost\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0: Preparing dataset\n",
      "Generating data for iteration 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating data: 100%|█████████████████████████████████████████████████████| 20000/20000 [00:10<00:00, 1862.58sample/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training BaseModel on fold 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:   0%|                                                                       | 0/10 [00:00<?, ?epoch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entrenando modelo...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\krr\\AppData\\Local\\Temp\\ipykernel_41328\\4009101619.py:79: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df = pd.concat([df, pd.DataFrame([{\n",
      "Training Epochs: 100%|██████████████████████████████████████████████████████████████| 10/10 [00:17<00:00,  1.75s/epoch]\n",
      "C:\\Users\\krr\\AppData\\Local\\Temp\\ipykernel_41328\\2211012613.py:69: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  train_df = pd.concat([train_df, pd.DataFrame([{\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating BaseModel on fold 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Instances: 100%|██████████████████████████████████████████████████████████████| 50/50 [00:00<00:00, 24927.52instance/s]\n",
      "Solving Instances:   0%|                                                                  | 0/50 [00:00<?, ?instance/s]C:\\Users\\krr\\AppData\\Local\\Temp\\ipykernel_41328\\2211012613.py:90: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  eval_df = pd.concat([eval_df, pd.DataFrame([{\n",
      "Solving Instances: 100%|█████████████████████████████████████████████████████████| 50/50 [00:05<00:00,  9.42instance/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training BaseModel on fold 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:   0%|                                                                       | 0/10 [00:00<?, ?epoch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entrenando modelo...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\krr\\AppData\\Local\\Temp\\ipykernel_41328\\4009101619.py:79: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df = pd.concat([df, pd.DataFrame([{\n",
      "Training Epochs: 100%|██████████████████████████████████████████████████████████████| 10/10 [00:14<00:00,  1.50s/epoch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating BaseModel on fold 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Instances: 100%|██████████████████████████████████████████████████████████████| 50/50 [00:00<00:00, 16677.15instance/s]\n",
      "Solving Instances: 100%|█████████████████████████████████████████████████████████| 50/50 [00:04<00:00, 10.42instance/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training BaseModel on fold 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:   0%|                                                                       | 0/10 [00:00<?, ?epoch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entrenando modelo...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\krr\\AppData\\Local\\Temp\\ipykernel_41328\\4009101619.py:79: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df = pd.concat([df, pd.DataFrame([{\n",
      "Training Epochs: 100%|██████████████████████████████████████████████████████████████| 10/10 [00:15<00:00,  1.51s/epoch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating BaseModel on fold 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Instances: 100%|██████████████████████████████████████████████████████████████| 50/50 [00:00<00:00, 19933.01instance/s]\n",
      "Solving Instances: 100%|█████████████████████████████████████████████████████████| 50/50 [00:05<00:00,  8.94instance/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training BaseModel on fold 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:   0%|                                                                       | 0/10 [00:00<?, ?epoch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entrenando modelo...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\krr\\AppData\\Local\\Temp\\ipykernel_41328\\4009101619.py:79: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df = pd.concat([df, pd.DataFrame([{\n",
      "Training Epochs: 100%|██████████████████████████████████████████████████████████████| 10/10 [00:16<00:00,  1.62s/epoch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating BaseModel on fold 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Instances: 100%|██████████████████████████████████████████████████████████████| 50/50 [00:00<00:00, 25007.77instance/s]\n",
      "Solving Instances: 100%|█████████████████████████████████████████████████████████| 50/50 [00:05<00:00,  9.40instance/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training BaseModel on fold 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:   0%|                                                                       | 0/10 [00:00<?, ?epoch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entrenando modelo...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\krr\\AppData\\Local\\Temp\\ipykernel_41328\\4009101619.py:79: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df = pd.concat([df, pd.DataFrame([{\n",
      "Training Epochs: 100%|██████████████████████████████████████████████████████████████| 10/10 [00:15<00:00,  1.52s/epoch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating BaseModel on fold 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Instances: 100%|██████████████████████████████████████████████████████████████| 50/50 [00:00<00:00, 25631.29instance/s]\n",
      "Solving Instances: 100%|█████████████████████████████████████████████████████████| 50/50 [00:04<00:00, 10.16instance/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training BaseModel on fold 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:   0%|                                                                       | 0/10 [00:00<?, ?epoch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entrenando modelo...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\krr\\AppData\\Local\\Temp\\ipykernel_41328\\4009101619.py:79: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df = pd.concat([df, pd.DataFrame([{\n",
      "Training Epochs: 100%|██████████████████████████████████████████████████████████████| 10/10 [00:15<00:00,  1.53s/epoch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating BaseModel on fold 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Instances: 100%|██████████████████████████████████████████████████████████████| 50/50 [00:00<00:00, 24963.12instance/s]\n",
      "Solving Instances: 100%|█████████████████████████████████████████████████████████| 50/50 [00:05<00:00,  9.24instance/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training BaseModel on fold 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:   0%|                                                                       | 0/10 [00:00<?, ?epoch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entrenando modelo...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\krr\\AppData\\Local\\Temp\\ipykernel_41328\\4009101619.py:79: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df = pd.concat([df, pd.DataFrame([{\n",
      "Training Epochs: 100%|██████████████████████████████████████████████████████████████| 10/10 [00:15<00:00,  1.51s/epoch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating BaseModel on fold 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Instances: 100%|██████████████████████████████████████████████████████████████| 50/50 [00:00<00:00, 27335.14instance/s]\n",
      "Solving Instances: 100%|█████████████████████████████████████████████████████████| 50/50 [00:04<00:00, 10.01instance/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training BaseModel on fold 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:   0%|                                                                       | 0/10 [00:00<?, ?epoch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entrenando modelo...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\krr\\AppData\\Local\\Temp\\ipykernel_41328\\4009101619.py:79: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df = pd.concat([df, pd.DataFrame([{\n",
      "Training Epochs: 100%|██████████████████████████████████████████████████████████████| 10/10 [00:16<00:00,  1.64s/epoch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating BaseModel on fold 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Instances: 100%|██████████████████████████████████████████████████████████████| 50/50 [00:00<00:00, 19988.11instance/s]\n",
      "Solving Instances: 100%|█████████████████████████████████████████████████████████| 50/50 [00:05<00:00,  9.14instance/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training BaseModel on fold 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:   0%|                                                                       | 0/10 [00:00<?, ?epoch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entrenando modelo...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\krr\\AppData\\Local\\Temp\\ipykernel_41328\\4009101619.py:79: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df = pd.concat([df, pd.DataFrame([{\n",
      "Training Epochs: 100%|██████████████████████████████████████████████████████████████| 10/10 [00:16<00:00,  1.63s/epoch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating BaseModel on fold 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Instances: 100%|██████████████████████████████████████████████████████████████| 50/50 [00:00<00:00, 25034.64instance/s]\n",
      "Solving Instances: 100%|█████████████████████████████████████████████████████████| 50/50 [00:04<00:00, 10.20instance/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training BaseModel on fold 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:   0%|                                                                       | 0/10 [00:00<?, ?epoch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entrenando modelo...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\krr\\AppData\\Local\\Temp\\ipykernel_41328\\4009101619.py:79: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df = pd.concat([df, pd.DataFrame([{\n",
      "Training Epochs: 100%|██████████████████████████████████████████████████████████████| 10/10 [00:15<00:00,  1.52s/epoch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating BaseModel on fold 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Instances: 100%|██████████████████████████████████████████████████████████████| 50/50 [00:00<00:00, 21879.52instance/s]\n",
      "Solving Instances: 100%|█████████████████████████████████████████████████████████| 50/50 [00:05<00:00,  9.26instance/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0: Preparing dataset\n",
      "Generating data for iteration 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating data: 100%|█████████████████████████████████████████████████████| 20000/20000 [00:10<00:00, 1822.80sample/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training TransformerBlockModel on fold 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:   0%|                                                                       | 0/10 [00:00<?, ?epoch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entrenando modelo...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\krr\\AppData\\Local\\Temp\\ipykernel_41328\\4009101619.py:79: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df = pd.concat([df, pd.DataFrame([{\n",
      "Training Epochs: 100%|██████████████████████████████████████████████████████████████| 10/10 [00:19<00:00,  1.97s/epoch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating TransformerBlockModel on fold 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Instances: 100%|██████████████████████████████████████████████████████████████| 50/50 [00:00<00:00, 25037.63instance/s]\n",
      "Solving Instances: 100%|█████████████████████████████████████████████████████████| 50/50 [00:05<00:00,  9.08instance/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training TransformerBlockModel on fold 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:   0%|                                                                       | 0/10 [00:00<?, ?epoch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entrenando modelo...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\krr\\AppData\\Local\\Temp\\ipykernel_41328\\4009101619.py:79: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df = pd.concat([df, pd.DataFrame([{\n",
      "Training Epochs: 100%|██████████████████████████████████████████████████████████████| 10/10 [00:20<00:00,  2.01s/epoch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating TransformerBlockModel on fold 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Instances: 100%|██████████████████████████████████████████████████████████████| 50/50 [00:00<00:00, 25001.81instance/s]\n",
      "Solving Instances: 100%|█████████████████████████████████████████████████████████| 50/50 [00:05<00:00,  8.55instance/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training TransformerBlockModel on fold 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:   0%|                                                                       | 0/10 [00:00<?, ?epoch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entrenando modelo...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\krr\\AppData\\Local\\Temp\\ipykernel_41328\\4009101619.py:79: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df = pd.concat([df, pd.DataFrame([{\n",
      "Training Epochs: 100%|██████████████████████████████████████████████████████████████| 10/10 [00:20<00:00,  2.02s/epoch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating TransformerBlockModel on fold 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Instances: 100%|██████████████████████████████████████████████████████████████| 50/50 [00:00<00:00, 19326.81instance/s]\n",
      "Solving Instances: 100%|█████████████████████████████████████████████████████████| 50/50 [00:05<00:00,  8.92instance/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training TransformerBlockModel on fold 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:   0%|                                                                       | 0/10 [00:00<?, ?epoch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entrenando modelo...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\krr\\AppData\\Local\\Temp\\ipykernel_41328\\4009101619.py:79: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df = pd.concat([df, pd.DataFrame([{\n",
      "Training Epochs: 100%|██████████████████████████████████████████████████████████████| 10/10 [00:19<00:00,  1.96s/epoch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating TransformerBlockModel on fold 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Instances: 100%|██████████████████████████████████████████████████████████████| 50/50 [00:00<00:00, 25019.71instance/s]\n",
      "Solving Instances: 100%|█████████████████████████████████████████████████████████| 50/50 [00:06<00:00,  8.13instance/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training TransformerBlockModel on fold 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:   0%|                                                                       | 0/10 [00:00<?, ?epoch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entrenando modelo...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\krr\\AppData\\Local\\Temp\\ipykernel_41328\\4009101619.py:79: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df = pd.concat([df, pd.DataFrame([{\n",
      "Training Epochs: 100%|██████████████████████████████████████████████████████████████| 10/10 [00:20<00:00,  2.10s/epoch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating TransformerBlockModel on fold 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Instances: 100%|██████████████████████████████████████████████████████████████| 50/50 [00:00<00:00, 19206.45instance/s]\n",
      "Solving Instances: 100%|█████████████████████████████████████████████████████████| 50/50 [00:05<00:00,  8.60instance/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training TransformerBlockModel on fold 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:   0%|                                                                       | 0/10 [00:00<?, ?epoch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entrenando modelo...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\krr\\AppData\\Local\\Temp\\ipykernel_41328\\4009101619.py:79: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df = pd.concat([df, pd.DataFrame([{\n",
      "Training Epochs: 100%|██████████████████████████████████████████████████████████████| 10/10 [00:19<00:00,  1.95s/epoch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating TransformerBlockModel on fold 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Instances: 100%|██████████████████████████████████████████████████████████████| 50/50 [00:00<00:00, 25013.74instance/s]\n",
      "Solving Instances: 100%|█████████████████████████████████████████████████████████| 50/50 [00:05<00:00,  8.95instance/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training TransformerBlockModel on fold 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:   0%|                                                                       | 0/10 [00:00<?, ?epoch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entrenando modelo...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\krr\\AppData\\Local\\Temp\\ipykernel_41328\\4009101619.py:79: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df = pd.concat([df, pd.DataFrame([{\n",
      "Training Epochs: 100%|██████████████████████████████████████████████████████████████| 10/10 [00:19<00:00,  1.98s/epoch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating TransformerBlockModel on fold 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Instances: 100%|██████████████████████████████████████████████████████████████| 50/50 [00:00<00:00, 19122.39instance/s]\n",
      "Solving Instances: 100%|█████████████████████████████████████████████████████████| 50/50 [00:05<00:00,  8.80instance/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training TransformerBlockModel on fold 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:   0%|                                                                       | 0/10 [00:00<?, ?epoch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entrenando modelo...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\krr\\AppData\\Local\\Temp\\ipykernel_41328\\4009101619.py:79: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df = pd.concat([df, pd.DataFrame([{\n",
      "Training Epochs: 100%|██████████████████████████████████████████████████████████████| 10/10 [00:19<00:00,  1.96s/epoch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating TransformerBlockModel on fold 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Instances: 100%|██████████████████████████████████████████████████████████████| 50/50 [00:00<00:00, 19380.39instance/s]\n",
      "Solving Instances: 100%|█████████████████████████████████████████████████████████| 50/50 [00:05<00:00,  8.41instance/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training TransformerBlockModel on fold 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:   0%|                                                                       | 0/10 [00:00<?, ?epoch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entrenando modelo...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\krr\\AppData\\Local\\Temp\\ipykernel_41328\\4009101619.py:79: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df = pd.concat([df, pd.DataFrame([{\n",
      "Training Epochs: 100%|██████████████████████████████████████████████████████████████| 10/10 [00:19<00:00,  1.95s/epoch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating TransformerBlockModel on fold 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Instances: 100%|██████████████████████████████████████████████████████████████| 50/50 [00:00<00:00, 25028.67instance/s]\n",
      "Solving Instances: 100%|█████████████████████████████████████████████████████████| 50/50 [00:05<00:00,  8.87instance/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training TransformerBlockModel on fold 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:   0%|                                                                       | 0/10 [00:00<?, ?epoch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entrenando modelo...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\krr\\AppData\\Local\\Temp\\ipykernel_41328\\4009101619.py:79: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df = pd.concat([df, pd.DataFrame([{\n",
      "Training Epochs: 100%|██████████████████████████████████████████████████████████████| 10/10 [00:20<00:00,  2.01s/epoch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating TransformerBlockModel on fold 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Instances: 100%|██████████████████████████████████████████████████████████████| 50/50 [00:00<00:00, 25028.67instance/s]\n",
      "Solving Instances: 100%|█████████████████████████████████████████████████████████| 50/50 [00:06<00:00,  8.24instance/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0: Preparing dataset\n",
      "Generating data for iteration 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating data: 100%|█████████████████████████████████████████████████████| 20000/20000 [00:10<00:00, 1824.76sample/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training MultilayerTransformerBlockModel on fold 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:   0%|                                                                       | 0/10 [00:00<?, ?epoch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entrenando modelo...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\krr\\AppData\\Local\\Temp\\ipykernel_41328\\4009101619.py:79: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df = pd.concat([df, pd.DataFrame([{\n",
      "Training Epochs: 100%|██████████████████████████████████████████████████████████████| 10/10 [00:51<00:00,  5.13s/epoch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating MultilayerTransformerBlockModel on fold 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Instances: 100%|██████████████████████████████████████████████████████████████| 50/50 [00:00<00:00, 16667.87instance/s]\n",
      "Solving Instances: 100%|█████████████████████████████████████████████████████████| 50/50 [00:12<00:00,  4.01instance/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training MultilayerTransformerBlockModel on fold 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:   0%|                                                                       | 0/10 [00:00<?, ?epoch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entrenando modelo...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\krr\\AppData\\Local\\Temp\\ipykernel_41328\\4009101619.py:79: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df = pd.concat([df, pd.DataFrame([{\n",
      "Training Epochs: 100%|██████████████████████████████████████████████████████████████| 10/10 [00:50<00:00,  5.02s/epoch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating MultilayerTransformerBlockModel on fold 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Instances: 100%|██████████████████████████████████████████████████████████████| 50/50 [00:00<00:00, 25004.79instance/s]\n",
      "Solving Instances: 100%|█████████████████████████████████████████████████████████| 50/50 [00:12<00:00,  4.10instance/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training MultilayerTransformerBlockModel on fold 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:   0%|                                                                       | 0/10 [00:00<?, ?epoch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entrenando modelo...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\krr\\AppData\\Local\\Temp\\ipykernel_41328\\4009101619.py:79: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df = pd.concat([df, pd.DataFrame([{\n",
      "Training Epochs: 100%|██████████████████████████████████████████████████████████████| 10/10 [00:52<00:00,  5.28s/epoch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating MultilayerTransformerBlockModel on fold 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Instances: 100%|██████████████████████████████████████████████████████████████| 50/50 [00:00<00:00, 25010.76instance/s]\n",
      "Solving Instances: 100%|█████████████████████████████████████████████████████████| 50/50 [00:11<00:00,  4.17instance/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training MultilayerTransformerBlockModel on fold 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:   0%|                                                                       | 0/10 [00:00<?, ?epoch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entrenando modelo...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\krr\\AppData\\Local\\Temp\\ipykernel_41328\\4009101619.py:79: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df = pd.concat([df, pd.DataFrame([{\n",
      "Training Epochs: 100%|██████████████████████████████████████████████████████████████| 10/10 [00:49<00:00,  4.98s/epoch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating MultilayerTransformerBlockModel on fold 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Instances: 100%|███████████████████████████████████████████████████████████████| 50/50 [00:00<00:00, 7089.76instance/s]\n",
      "Solving Instances: 100%|█████████████████████████████████████████████████████████| 50/50 [00:12<00:00,  4.13instance/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training MultilayerTransformerBlockModel on fold 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:   0%|                                                                       | 0/10 [00:00<?, ?epoch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entrenando modelo...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\krr\\AppData\\Local\\Temp\\ipykernel_41328\\4009101619.py:79: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df = pd.concat([df, pd.DataFrame([{\n",
      "Training Epochs: 100%|██████████████████████████████████████████████████████████████| 10/10 [00:50<00:00,  5.07s/epoch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating MultilayerTransformerBlockModel on fold 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Instances: 100%|██████████████████████████████████████████████████████████████| 50/50 [00:00<00:00, 16671.85instance/s]\n",
      "Solving Instances: 100%|█████████████████████████████████████████████████████████| 50/50 [00:11<00:00,  4.18instance/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training MultilayerTransformerBlockModel on fold 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:   0%|                                                                       | 0/10 [00:00<?, ?epoch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entrenando modelo...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\krr\\AppData\\Local\\Temp\\ipykernel_41328\\4009101619.py:79: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df = pd.concat([df, pd.DataFrame([{\n",
      "Training Epochs: 100%|██████████████████████████████████████████████████████████████| 10/10 [00:51<00:00,  5.13s/epoch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating MultilayerTransformerBlockModel on fold 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Instances: 100%|██████████████████████████████████████████████████████████████| 50/50 [00:00<00:00, 24989.90instance/s]\n",
      "Solving Instances: 100%|█████████████████████████████████████████████████████████| 50/50 [00:12<00:00,  4.07instance/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training MultilayerTransformerBlockModel on fold 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:   0%|                                                                       | 0/10 [00:00<?, ?epoch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entrenando modelo...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\krr\\AppData\\Local\\Temp\\ipykernel_41328\\4009101619.py:79: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df = pd.concat([df, pd.DataFrame([{\n",
      "Training Epochs: 100%|██████████████████████████████████████████████████████████████| 10/10 [00:50<00:00,  5.04s/epoch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating MultilayerTransformerBlockModel on fold 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Instances: 100%|██████████████████████████████████████████████████████████████| 50/50 [00:00<00:00, 16325.33instance/s]\n",
      "Solving Instances: 100%|█████████████████████████████████████████████████████████| 50/50 [00:11<00:00,  4.19instance/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training MultilayerTransformerBlockModel on fold 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:   0%|                                                                       | 0/10 [00:00<?, ?epoch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entrenando modelo...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\krr\\AppData\\Local\\Temp\\ipykernel_41328\\4009101619.py:79: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df = pd.concat([df, pd.DataFrame([{\n",
      "Training Epochs: 100%|██████████████████████████████████████████████████████████████| 10/10 [00:50<00:00,  5.08s/epoch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating MultilayerTransformerBlockModel on fold 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Instances: 100%|██████████████████████████████████████████████████████████████| 50/50 [00:00<00:00, 19881.99instance/s]\n",
      "Solving Instances: 100%|█████████████████████████████████████████████████████████| 50/50 [00:12<00:00,  4.03instance/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training MultilayerTransformerBlockModel on fold 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:   0%|                                                                       | 0/10 [00:00<?, ?epoch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entrenando modelo...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\krr\\AppData\\Local\\Temp\\ipykernel_41328\\4009101619.py:79: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df = pd.concat([df, pd.DataFrame([{\n",
      "Training Epochs: 100%|██████████████████████████████████████████████████████████████| 10/10 [00:51<00:00,  5.17s/epoch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating MultilayerTransformerBlockModel on fold 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Instances: 100%|██████████████████████████████████████████████████████████████| 50/50 [00:00<00:00, 13437.25instance/s]\n",
      "Solving Instances: 100%|█████████████████████████████████████████████████████████| 50/50 [00:14<00:00,  3.53instance/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training MultilayerTransformerBlockModel on fold 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:   0%|                                                                       | 0/10 [00:00<?, ?epoch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entrenando modelo...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\krr\\AppData\\Local\\Temp\\ipykernel_41328\\4009101619.py:79: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df = pd.concat([df, pd.DataFrame([{\n",
      "Training Epochs: 100%|██████████████████████████████████████████████████████████████| 10/10 [00:59<00:00,  5.96s/epoch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating MultilayerTransformerBlockModel on fold 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Instances: 100%|██████████████████████████████████████████████████████████████| 50/50 [00:00<00:00, 16256.99instance/s]\n",
      "Solving Instances: 100%|█████████████████████████████████████████████████████████| 50/50 [00:14<00:00,  3.47instance/s]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "from eda.TSP import TSP_Instance, TSP_Environment, TSP_State, evalConstructiveActions, plot_tour\n",
    "from eda.agents import SingleAgentSolver, GreedyAgent\n",
    "nb_cities = 50\n",
    "nb_samples=20000\n",
    "nb_eval = 50\n",
    "k_folds=10\n",
    "iter=0\n",
    "models = [BaseModel(), TransformerBlockModel(), MultilayerTransformerBlockModel()]\n",
    "class ModelEvalActions():\n",
    "  def __init__(self, model):\n",
    "    self.model=model\n",
    "\n",
    "  # permite evaluar acctiones de varios estados a la vez\n",
    "  # para optimizar los cáluclos del modelo\n",
    "  def __call__(self, states, env):\n",
    "    single_state = False\n",
    "    if not isinstance(states, list):\n",
    "      single_state=True\n",
    "      states = [states]\n",
    "\n",
    "    evals = [list() for _ in states]\n",
    "    vecSeqs=[]; move2idx =[]\n",
    "\n",
    "    for state in states:\n",
    "      vecSeq, _, mov2idx = state.state2vecSeq()\n",
    "      vecSeqs.append(vecSeq)\n",
    "      move2idx.append(mov2idx)\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    predictions = self.model(torch.tensor(vecSeqs).to(device), return_probabilities=True)\n",
    "\n",
    "    for k in range(len(states)):\n",
    "      state = states[k]\n",
    "      for action in env.gen_actions(state, \"constructive\"):\n",
    "          idx = move2idx[k][action[1]] #mapping from move to output index (model)\n",
    "          evals[k].append((action,predictions[k][idx]))\n",
    "\n",
    "    if single_state: return evals[0]\n",
    "    else: return evals\n",
    "\n",
    "\n",
    "for model in models:\n",
    "        print(f\"Iteration {iter}: Preparing dataset\")\n",
    "\n",
    "        # Generate data once per iteration\n",
    "        print(f\"Generating data for iteration {iter}\")\n",
    "        X, Y = model.generate_data(use_progress_bar=True)\n",
    "        X = X.to(model.device)\n",
    "        Y = Y.to(model.device)\n",
    "\n",
    "        kfold = KFold(n_splits=k_folds, shuffle=True, random_state=iter)\n",
    "        fold = 0\n",
    "\n",
    "        for train_idx, val_idx in kfold.split(X):\n",
    "            fold += 1\n",
    "\n",
    "            print(f\"Training {type(model).__name__} on fold {fold}\")\n",
    "\n",
    "            # Split data into train and validation sets\n",
    "            X_train, X_val = X[train_idx], X[val_idx]\n",
    "            Y_train, Y_val = Y[train_idx], Y[val_idx]\n",
    "\n",
    "            model.load_model()\n",
    "            # Train the model\n",
    "            trained_model_df = model.train(X_train, Y_train, X_val, Y_val, use_progress_bar=True)\n",
    "                        # Log training metrics\n",
    "            for _, row in trained_model_df.iterrows():\n",
    "                train_df = pd.concat([train_df, pd.DataFrame([{\n",
    "                    \"model_name\": type(model).__name__,\n",
    "                    \"fold\": fold,\n",
    "                    \"epoch\": row[\"Epoch\"],\n",
    "                    \"tr_loss\": row[\"Training Loss\"],\n",
    "                    \"tr_acc\": row[\"Training Accuracy\"],\n",
    "                    \"val_loss\": row[\"Validation Loss\"],\n",
    "                    \"val_acc\": row[\"Validation Accuracy\"]\n",
    "                }])])\n",
    "\n",
    "            print(f\"Evaluating {type(model).__name__} on fold {fold}\")\n",
    "            instances = [\n",
    "                TSP_Instance(np.random.rand(model.city_count, 2)) for _ in tqdm(\n",
    "                    range(nb_eval), desc=\"Instances\", unit=\"instance\", position=0, leave=True\n",
    "                )\n",
    "            ]\n",
    "            greedy = SingleAgentSolver(env, GreedyAgent(ModelEvalActions(model.model)))\n",
    "            solutions = []\n",
    "\n",
    "            for instance in tqdm(instances, desc=\"Solving Instances\", unit=\"instance\", position=0, leave=True):\n",
    "                solution, *_ = greedy.solve(TSP_State(instance, visited=[0]))\n",
    "                eval_df = pd.concat([eval_df, pd.DataFrame([{\n",
    "                    \"model_name\" : type(model).__name__,\n",
    "                    \"fold\": fold,\n",
    "                    \"cost\": solution.cost,                \n",
    "            }]) ])\n",
    "\n",
    "            model.unload_model()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_name</th>\n",
       "      <th>fold</th>\n",
       "      <th>epoch</th>\n",
       "      <th>tr_loss</th>\n",
       "      <th>tr_acc</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>val_acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BaseModel</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.555729</td>\n",
       "      <td>58.283333</td>\n",
       "      <td>0.599872</td>\n",
       "      <td>82.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BaseModel</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.618517</td>\n",
       "      <td>80.038889</td>\n",
       "      <td>0.530862</td>\n",
       "      <td>83.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BaseModel</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.587735</td>\n",
       "      <td>80.783333</td>\n",
       "      <td>0.556028</td>\n",
       "      <td>83.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BaseModel</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0.577756</td>\n",
       "      <td>81.072222</td>\n",
       "      <td>0.525841</td>\n",
       "      <td>83.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BaseModel</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0.566840</td>\n",
       "      <td>81.750000</td>\n",
       "      <td>0.510448</td>\n",
       "      <td>83.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MultilayerTransformerBlockModel</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>0.550962</td>\n",
       "      <td>81.950000</td>\n",
       "      <td>0.490693</td>\n",
       "      <td>85.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MultilayerTransformerBlockModel</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>0.547259</td>\n",
       "      <td>81.861111</td>\n",
       "      <td>0.526866</td>\n",
       "      <td>84.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MultilayerTransformerBlockModel</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>0.551965</td>\n",
       "      <td>81.983333</td>\n",
       "      <td>0.508395</td>\n",
       "      <td>85.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MultilayerTransformerBlockModel</td>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "      <td>0.540237</td>\n",
       "      <td>82.166667</td>\n",
       "      <td>0.488472</td>\n",
       "      <td>85.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MultilayerTransformerBlockModel</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>0.536769</td>\n",
       "      <td>82.650000</td>\n",
       "      <td>0.484560</td>\n",
       "      <td>85.45</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>300 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                         model_name fold epoch   tr_loss     tr_acc  val_loss  \\\n",
       "0                         BaseModel    1     1  1.555729  58.283333  0.599872   \n",
       "0                         BaseModel    1     2  0.618517  80.038889  0.530862   \n",
       "0                         BaseModel    1     3  0.587735  80.783333  0.556028   \n",
       "0                         BaseModel    1     4  0.577756  81.072222  0.525841   \n",
       "0                         BaseModel    1     5  0.566840  81.750000  0.510448   \n",
       "..                              ...  ...   ...       ...        ...       ...   \n",
       "0   MultilayerTransformerBlockModel   10     6  0.550962  81.950000  0.490693   \n",
       "0   MultilayerTransformerBlockModel   10     7  0.547259  81.861111  0.526866   \n",
       "0   MultilayerTransformerBlockModel   10     8  0.551965  81.983333  0.508395   \n",
       "0   MultilayerTransformerBlockModel   10     9  0.540237  82.166667  0.488472   \n",
       "0   MultilayerTransformerBlockModel   10    10  0.536769  82.650000  0.484560   \n",
       "\n",
       "    val_acc  \n",
       "0     82.35  \n",
       "0     83.05  \n",
       "0     83.35  \n",
       "0     83.35  \n",
       "0     83.95  \n",
       "..      ...  \n",
       "0     85.20  \n",
       "0     84.80  \n",
       "0     85.45  \n",
       "0     85.15  \n",
       "0     85.45  \n",
       "\n",
       "[300 rows x 7 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_name</th>\n",
       "      <th>fold</th>\n",
       "      <th>cost</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BaseModel</td>\n",
       "      <td>1</td>\n",
       "      <td>6.797305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BaseModel</td>\n",
       "      <td>1</td>\n",
       "      <td>6.305213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BaseModel</td>\n",
       "      <td>1</td>\n",
       "      <td>6.239691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BaseModel</td>\n",
       "      <td>1</td>\n",
       "      <td>6.563191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BaseModel</td>\n",
       "      <td>1</td>\n",
       "      <td>7.003203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MultilayerTransformerBlockModel</td>\n",
       "      <td>10</td>\n",
       "      <td>6.766856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MultilayerTransformerBlockModel</td>\n",
       "      <td>10</td>\n",
       "      <td>6.136618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MultilayerTransformerBlockModel</td>\n",
       "      <td>10</td>\n",
       "      <td>6.017674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MultilayerTransformerBlockModel</td>\n",
       "      <td>10</td>\n",
       "      <td>6.733908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MultilayerTransformerBlockModel</td>\n",
       "      <td>10</td>\n",
       "      <td>6.155592</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1500 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                         model_name fold      cost\n",
       "0                         BaseModel    1  6.797305\n",
       "0                         BaseModel    1  6.305213\n",
       "0                         BaseModel    1  6.239691\n",
       "0                         BaseModel    1  6.563191\n",
       "0                         BaseModel    1  7.003203\n",
       "..                              ...  ...       ...\n",
       "0   MultilayerTransformerBlockModel   10  6.766856\n",
       "0   MultilayerTransformerBlockModel   10  6.136618\n",
       "0   MultilayerTransformerBlockModel   10  6.017674\n",
       "0   MultilayerTransformerBlockModel   10  6.733908\n",
       "0   MultilayerTransformerBlockModel   10  6.155592\n",
       "\n",
       "[1500 rows x 3 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_name</th>\n",
       "      <th>fold</th>\n",
       "      <th>cost</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BaseModel</td>\n",
       "      <td>1</td>\n",
       "      <td>5.927755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BaseModel</td>\n",
       "      <td>1</td>\n",
       "      <td>6.535351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BaseModel</td>\n",
       "      <td>1</td>\n",
       "      <td>6.602594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BaseModel</td>\n",
       "      <td>1</td>\n",
       "      <td>6.763597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BaseModel</td>\n",
       "      <td>1</td>\n",
       "      <td>7.058743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1495</th>\n",
       "      <td>MultilayerTransformerBlockModel</td>\n",
       "      <td>10</td>\n",
       "      <td>7.180407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1496</th>\n",
       "      <td>MultilayerTransformerBlockModel</td>\n",
       "      <td>10</td>\n",
       "      <td>6.208302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1497</th>\n",
       "      <td>MultilayerTransformerBlockModel</td>\n",
       "      <td>10</td>\n",
       "      <td>5.976801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1498</th>\n",
       "      <td>MultilayerTransformerBlockModel</td>\n",
       "      <td>10</td>\n",
       "      <td>6.413471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1499</th>\n",
       "      <td>MultilayerTransformerBlockModel</td>\n",
       "      <td>10</td>\n",
       "      <td>6.786273</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1500 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                           model_name fold      cost\n",
       "0                           BaseModel    1  5.927755\n",
       "1                           BaseModel    1  6.535351\n",
       "2                           BaseModel    1  6.602594\n",
       "3                           BaseModel    1  6.763597\n",
       "4                           BaseModel    1  7.058743\n",
       "...                               ...  ...       ...\n",
       "1495  MultilayerTransformerBlockModel   10  7.180407\n",
       "1496  MultilayerTransformerBlockModel   10  6.208302\n",
       "1497  MultilayerTransformerBlockModel   10  5.976801\n",
       "1498  MultilayerTransformerBlockModel   10  6.413471\n",
       "1499  MultilayerTransformerBlockModel   10  6.786273\n",
       "\n",
       "[1500 rows x 3 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ex_traindf = train_df.reset_index().drop('index', axis=1)\n",
    "ex_evaldf = eval_df.reset_index().drop('index', axis=1)\n",
    "ex_evaldf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "ex_traindf.to_csv(\"train_df.csv\")\n",
    "ex_evaldf.to_csv(\"eval_df.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
