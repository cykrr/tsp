{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "95f0f2d5-6463-433c-a95e-95cbc7c3523e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tsp.models import BaseModel, TransformerBlockModel, MultilayerTransformerBlockModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "22f74816-2567-4961-a0a2-be645c829c88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating data for MultilayerTransformerBlockModel...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating data: 100%|█████████████████████████████████████████████████████| 20000/20000 [00:10<00:00, 1982.17sample/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training MultilayerTransformerBlockModel...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:   0%|                                                                       | 0/10 [00:00<?, ?epoch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entrenando modelo...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\krr\\Downloads\\TSP\\tsp\\models\\trainable_model.py:83: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df = pd.concat([df, pd.DataFrame([{\n",
      "Training Epochs:  30%|██████████████████▉                                            | 3/10 [00:23<00:53,  7.70s/epoch]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 37\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTraining \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(model)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     36\u001b[0m model\u001b[38;5;241m.\u001b[39mload_model()\n\u001b[1;32m---> 37\u001b[0m model\u001b[38;5;241m.\u001b[39mtrain(\n\u001b[0;32m     38\u001b[0m     xt\u001b[38;5;241m=\u001b[39mtrain_X, \n\u001b[0;32m     39\u001b[0m     yt\u001b[38;5;241m=\u001b[39mtrain_Y, \n\u001b[0;32m     40\u001b[0m     xv\u001b[38;5;241m=\u001b[39mval_X, \n\u001b[0;32m     41\u001b[0m     yv\u001b[38;5;241m=\u001b[39mval_Y, \n\u001b[0;32m     42\u001b[0m     num_iter\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,  \u001b[38;5;66;03m# Example: Assuming this is the first iteration\u001b[39;00m\n\u001b[0;32m     43\u001b[0m     use_progress_bar\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m     44\u001b[0m )\n\u001b[0;32m     45\u001b[0m \u001b[38;5;66;03m# Save the trained model\u001b[39;00m\n\u001b[0;32m     46\u001b[0m time_stamp \u001b[38;5;241m=\u001b[39m datetime\u001b[38;5;241m.\u001b[39mdatetime\u001b[38;5;241m.\u001b[39mnow()\u001b[38;5;241m.\u001b[39mstrftime(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124my-\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mm-\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m--\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mH-\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mM-\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mS\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\Downloads\\TSP\\tsp\\models\\trainable_model.py:74\u001b[0m, in \u001b[0;36mTrainableModel.train\u001b[1;34m(self, xt, yt, xv, yv, num_iter, use_progress_bar)\u001b[0m\n\u001b[0;32m     72\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel(X_batch)\n\u001b[0;32m     73\u001b[0m loss \u001b[38;5;241m=\u001b[39m loss_function(outputs, y_batch\u001b[38;5;241m.\u001b[39margmax(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m))\n\u001b[1;32m---> 74\u001b[0m validation_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem() \u001b[38;5;241m*\u001b[39m X_batch\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m     75\u001b[0m _, predicted \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mmax(outputs\u001b[38;5;241m.\u001b[39mdata, \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     76\u001b[0m total \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m y_batch\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from tsp.models import BaseModel, TransformerBlockModel, MultilayerTransformerBlockModel\n",
    "from torch.utils.data import DataLoader, TensorDataset, random_split\n",
    "\n",
    "\n",
    "\n",
    "# List of models to train\n",
    "models = [#BaseModel(), TransformerBlockModel(), \n",
    "          MultilayerTransformerBlockModel()]\n",
    "\n",
    "# Device configuration\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Training loop for each model\n",
    "for model in models:\n",
    "    # Ensure the model is on the correct device\n",
    "    # Generate synthetic data\n",
    "    print(f\"Generating data for {type(model).__name__}...\")\n",
    "    X, Y = model.generate_data(use_progress_bar=True)\n",
    "    X, Y = X.to(device), Y.to(device)\n",
    "\n",
    "    # Split data into training and testing datasets\n",
    "    train_X, val_X, train_Y, val_Y = train_test_split(X, Y, test_size=0.5, random_state=42)\n",
    "    train_dataset = TensorDataset(train_X, train_Y)\n",
    "    val_dataset = TensorDataset(val_X, val_Y)\n",
    "\n",
    "    # Create data loaders\n",
    "    train_loader = DataLoader(train_dataset, batch_size=model.batch_size, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=model.batch_size, shuffle=False)\n",
    "\n",
    "    # Train the model\n",
    "    print(f\"Training {type(model).__name__}...\")\n",
    "    model.load_model()\n",
    "    dfa, dfb = model.train(\n",
    "        xt=train_X, \n",
    "        yt=train_Y, \n",
    "        xv=val_X, \n",
    "        yv=val_Y, \n",
    "        num_iter=1,  # Example: Assuming this is the first iteration\n",
    "        use_progress_bar=True\n",
    "    )\n",
    "    # Save the trained model\n",
    "    time_stamp = datetime.datetime.now().strftime(\"%y-%m-%d--%H-%M-%S\")\n",
    "    save_path = f\"{type(model).__name__}-{time_stamp}.bin\"\n",
    "    torch.save(model.model.state_dict(), save_path)\n",
    "    print(f\"Saved {type(model).__name__} to {save_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e550f1ed-6807-4a26-80d1-871ae152be89",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9779e180-ef90-41ca-8123-e3da37810c8f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
