{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zQP708EbgE6j"
   },
   "source": [
    "Se compara el desempeño entre los siguientes modelos/solvers:\n",
    "\n",
    "* Modelo base\n",
    "* Modelo bloque Transformer\n",
    "* Modelo bloque Transformer * 6\n",
    "* Modelo con encoding posicional\n",
    "* Greedy\n",
    "* OR-Tools\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Descarga de librerías"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uXy_uobPgEt1",
    "outputId": "9d951eb9-25de-4968-effd-168da4625519"
   },
   "outputs": [],
   "source": [
    "# Descarga de librerías\n",
    "\n",
    "# Linux only, doesn't work on windows\n",
    "# ! python -c \"import ortools\" 2>/dev/null  && echo \"OR-Tools is already installed\" || pip install ortools -q\n",
    "# ! [[ ! -d eda ]]  && echo \"Downloading eda repo\" && curl -L  https://github.com/rilianx/eda/archive/refs/heads/main.tar.gz | tar xzvf - && mv eda-main eda\n",
    "# import torch\n",
    "# !pip install tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! curl -LO https://github.com/rilianx/eda/archive/refs/heads/main.tar.gz\n",
    "# ! 7z x main.tar.gz\n",
    "# ! 7z x main.tar\n",
    "# ! move eda-main eda\n",
    "# ! del main.tar.gz\n",
    "# ! del main.tar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## state2vecSeq\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "41HRC0zLhJ9P",
    "outputId": "623e161d-65ab-43b9-b402-c75ea81c6dd7"
   },
   "outputs": [],
   "source": [
    "# Generación de datos\n",
    "\n",
    "\n",
    "from copy import deepcopy\n",
    "import random\n",
    "import math\n",
    "\n",
    "import numpy as np\n",
    "from torch.nn.functional import one_hot\n",
    "from eda.TSP import TSP_Instance, TSP_Environment, TSP_State\n",
    "from eda.solveTSP_v2 import solve\n",
    "env = TSP_Environment\n",
    "\n",
    "def distance(punto1, punto2):\n",
    "    return math.sqrt((punto1[0] - punto2[0])**2 + (punto1[1] - punto2[1])**2)\n",
    "\n",
    "# función para transformar un estado tsp en una secuencia de vectores\n",
    "# para el modelo basado en capas de atención\n",
    "def state2vecSeq(self):\n",
    "    # creamos dos diccionarios para mantenre un mapeo de los\n",
    "    # movimientos con los índices de la secuencia del modelo de aprendizaje\n",
    "\n",
    "    city_locations = self.inst_info.city_locations\n",
    "\n",
    "    idx2move = dict()\n",
    "    move2idx = dict()\n",
    "    origin = city_locations[self.visited[-1]]\n",
    "    destination = city_locations[self.visited[0]]\n",
    "\n",
    "    origin_dist = 0.0\n",
    "    dest_dist = distance(origin, destination)\n",
    "\n",
    "    seq = [list(origin) + [1,0] + [origin_dist, dest_dist], # Última ciudad visitada (origen)\n",
    "           list(destination) + [0, 1] + [dest_dist, 0.0]]  # Ciudad final\n",
    "\n",
    "    idx2move[0] = None\n",
    "    idx2move[1] = (\"constructive\", self.visited[0])\n",
    "    move2idx[self.visited[0]] = 1\n",
    "\n",
    "    idx = 2\n",
    "    for i in self.not_visited:\n",
    "        point = list(city_locations[i])\n",
    "        origin_dist = distance( point, origin)\n",
    "        dest_dist = distance( point, destination)\n",
    "        city_vector = point + [0, 0] + [origin_dist, dest_dist] # Otras ciudades\n",
    "\n",
    "        seq.append(city_vector)\n",
    "        idx2move[idx] = (\"constructive\", i)\n",
    "        move2idx[i] = idx\n",
    "        idx += 1\n",
    "\n",
    "    return seq, idx2move, move2idx\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Meta clase para definir modelos y ciclo de entrenamiento\n",
    "\n",
    "Se definen hiperparámetros de los modelos a evaluar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vf7E9wqajd6_",
    "outputId": "de948908-2df5-4c1c-e8ec-090b370758e9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.Model at 0x1965901bd50>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Todos los modelos serán entrenados con el mismo dataset\n",
    "# X: [20000, 11, 6], Y: [20000, 11]\n",
    "# donde X: (nb_sample, max_cities + 1, param_count), Y: (nb_sample, max_cities+1)\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "class Model:\n",
    "    # El modelo se genera en el constructor y se guarda en self.model\n",
    "    def __init__(self, \n",
    "         input_dim = 6,\n",
    "         num_heads = 10,\n",
    "         head_dim = 64,\n",
    "         city_count = 50,\n",
    "                 \n",
    "         batch_size = 512,\n",
    "         train_split = 0.5,\n",
    "         nb_samples = 20000,\n",
    "         epochs = 10):\n",
    "\n",
    "        self.city_count = city_count # Número de ciudades a evaluar\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "        ## Parámetros modelo\n",
    "        self.input_dim = input_dim  # Dimensión de la entrada\n",
    "        self.num_heads = num_heads  # Número de cabezas en la atención multi-cabeza\n",
    "        self.head_dim = head_dim  # Dimensión de cada cabeza\n",
    "        ## Parámetros entrenamiento\n",
    "        self.batch_size = batch_size\n",
    "        self.train_split = train_split\n",
    "        self.nb_samples = nb_samples\n",
    "        self.epochs = 10\n",
    "\n",
    "        \n",
    "        self.model = None\n",
    "    \n",
    "    \n",
    "    def load_model(self):\n",
    "        raise NotImplementedError(\"La función 'load_model' debe ser declarada\")\n",
    "    def unload_model(self):\n",
    "        raise NotImplementedError(\"La función 'unload_model' debe ser implementada\");\n",
    "\n",
    "    def train(self, x, y):\n",
    "        raise NotImplementedError(\"La función 'train' debe ser declarada\")\n",
    "      \n",
    "\n",
    "    def generate_data(self, use_progress_bar=False):\n",
    "        X = []  # Lista para almacenar las secuencias de entrada\n",
    "        Y = []  # Lista para almacenar las etiquetas objetivo (las siguientes ciudades a visitar)\n",
    "        seq_len = self.city_count + 1  # Longitud de la secuencia, ajustada para incluir una ciudad extra\n",
    "        \n",
    "        # If the flag is set, initialize the progress bar\n",
    "        pbar = tqdm(total=self.nb_samples, desc=\"Generating data\", unit=\"sample\", position=0, leave=True) if use_progress_bar else None\n",
    "        \n",
    "        # Bucle para generar datos hasta alcanzar el número deseado de muestras\n",
    "        while True:\n",
    "            # 1. Generamos instancia aleatoria\n",
    "            n_cities = self.city_count\n",
    "            dim = 2  # Dimensión para las coordenadas de la ciudad (2D: x, y)\n",
    "            city_points = np.random.rand(n_cities, dim)  # Generar puntos aleatorios para las ciudades\n",
    "            inst_info = TSP_Instance(city_points)\n",
    "    \n",
    "            # 2. Resolvemos TSP usando algoritmo tradicional\n",
    "            solution = solve(city_points)  # Resolver el TSP y obtener un estado final\n",
    "    \n",
    "            # 3. Iteramos sobre los movimientos de la solución final para generar varias muestras:\n",
    "            # estado (X) -> movimiento (Y)\n",
    "            current_state = TSP_State(inst_info)\n",
    "            env.state_transition(current_state, (\"constructive\", solution.visited[0]))\n",
    "            samples_per_sol = self.city_count - 1  # Número máximo de muestras por solución\n",
    "            \n",
    "            for move in [(\"constructive\", city) for city in solution.visited[1:]]:\n",
    "                seq, _, move2idx = state2vecSeq(current_state)  # Convertir el estado actual a secuencia vectorizada\n",
    "    \n",
    "                X.append(torch.tensor(seq))  # Añadir la secuencia a X\n",
    "                Y.append(one_hot(torch.tensor(move2idx[move[1]]), num_classes=seq_len))\n",
    "                #Y.append(to_categorical(move2idx[move[1]], num_classes=seq_len))  # Añadir el movimiento como categoría a Y\n",
    "    \n",
    "                env.state_transition(current_state, move)  # Hacer la transición al siguiente estado\n",
    "    \n",
    "                # Actualizar el progreso de la barra si se está usando\n",
    "                if use_progress_bar:\n",
    "                    pbar.update(1)\n",
    "    \n",
    "                # Condiciones de parada basadas en el número de ciudades visitadas/no visitadas o muestras generadas\n",
    "                if len(current_state.visited) > samples_per_sol or len(X) >= self.nb_samples:\n",
    "                    break\n",
    "    \n",
    "            # Romper el bucle externo si se ha alcanzado el número deseado de muestras\n",
    "            if len(X) >= self.nb_samples:\n",
    "                break\n",
    "        \n",
    "        # Close the progress bar if it was used\n",
    "        if use_progress_bar:\n",
    "            pbar.close()\n",
    "    \n",
    "        X_padded = torch.nn.utils.rnn.pad_sequence(X, batch_first=True)\n",
    "        \n",
    "        return X_padded, torch.stack(Y)\n",
    "\n",
    "\n",
    "Model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "m9yrvnSSnDeT"
   },
   "outputs": [],
   "source": [
    "## Definición base de modelo para usar el mismo entrenamiento en los distintos modelos\n",
    "import pandas as pd\n",
    "import gc\n",
    "from eda.agents import GreedyAgent, SingleAgentSolver\n",
    "from tsp.model_eval_actions import ModelEvalActions\n",
    "class TrainableModel(Model):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # Parámetros del modelo\n",
    "    def unload_model(self):\n",
    "        del model.model\n",
    "        torch.cuda.empty_cache()\n",
    "        gc.collect()\n",
    "\n",
    "    def train(self, xt, yt, xv, yv, num_iter=-1, use_progress_bar=False):\n",
    "        # self.load_model()\n",
    "        # Asumiendo que X_padded y Y_stacked ya están definidos y son tensores de PyTorch\n",
    "        trd = TensorDataset(xt, yt)\n",
    "        ted = TensorDataset(xv, yv)\n",
    "    \n",
    "        # # Dividir el dataset en entrenamiento y prueba\n",
    "        # train_size = int(self.train_split * len(dataset))\n",
    "        # test_size = len(dataset) - train_size\n",
    "        train_dataset, test_dataset = trd, ted\n",
    "    \n",
    "        train_loader = DataLoader(train_dataset, batch_size=self.batch_size, shuffle=True)\n",
    "        test_loader = DataLoader(test_dataset, batch_size=self.batch_size, shuffle=False)\n",
    "    \n",
    "        # Definir el modelo, la función de pérdida y el optimizador\n",
    "        loss_function = torch.nn.CrossEntropyLoss()\n",
    "        optimizer = torch.optim.Adam(self.model.parameters(),lr=1e-4)\n",
    "    \n",
    "        # Initialize the DataFrame to store training results\n",
    "        df = pd.DataFrame(columns=[\"Model Name\", \"cities\", \"iter\", \"Epoch\",\n",
    "                                   \"Training Loss\", \"Training Accuracy\",\n",
    "                                   \"Validation Loss\", \"Validation Accuracy\"])\n",
    "        dfb = pd.DataFrame(columns=[\"Model Name\", \"cities\", \"iter\", \"Epoch\", \"cost\"])\n",
    "    \n",
    "        # Initialize the progress bar for epochs if required\n",
    "        epoch_range = range(self.epochs)\n",
    "        if use_progress_bar:\n",
    "            epoch_range = tqdm(epoch_range, desc=\"Training Epochs\", unit=\"epoch\", position = 0, leave = True)\n",
    "        \n",
    "        print(\"Entrenando modelo...\")\n",
    "        for epoch in epoch_range:\n",
    "            self.model.train()\n",
    "            train_loss = 0\n",
    "            correct = 0\n",
    "            total = 0\n",
    "            for X_batch, y_batch in train_loader:\n",
    "                optimizer.zero_grad()  # Limpia los gradientes\n",
    "                outputs = self.model(X_batch)  # Obtenemos logits\n",
    "                loss = loss_function(outputs, y_batch.argmax(dim=1))  # Calcular la pérdida\n",
    "                loss.backward()  # Backward pass\n",
    "                optimizer.step()  # Actualizar parámetros\n",
    "                train_loss += loss.item() * X_batch.size(0)\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                total += y_batch.size(0)\n",
    "                correct += (predicted == y_batch.argmax(dim=1)).sum().item()\n",
    "    \n",
    "            train_loss /= len(train_loader.dataset)\n",
    "            train_accuracy = 100 * correct / total\n",
    "    \n",
    "            # Validación\n",
    "            self.model.eval()\n",
    "            validation_loss = 0\n",
    "            correct = 0\n",
    "            total = 0\n",
    "            with torch.no_grad():\n",
    "                for X_batch, y_batch in test_loader:\n",
    "                    outputs = self.model(X_batch)\n",
    "                    loss = loss_function(outputs, y_batch.argmax(dim=1))\n",
    "                    validation_loss += loss.item() * X_batch.size(0)\n",
    "                    _, predicted = torch.max(outputs.data, 1)\n",
    "                    total += y_batch.size(0)\n",
    "                    correct += (predicted == y_batch.argmax(dim=1)).sum().item()\n",
    "    \n",
    "            validation_loss /= len(test_loader.dataset)\n",
    "            validation_accuracy = 100 * correct / total\n",
    "    \n",
    "            # Log results to DataFrame\n",
    "            df = pd.concat([df, pd.DataFrame([{\n",
    "                \"Model Name\": type(self).__name__,\n",
    "                \"cities\": self.city_count,\n",
    "                \"iter\": num_iter,\n",
    "                \"Epoch\": epoch + 1,\n",
    "                \"Training Loss\": train_loss,\n",
    "                \"Training Accuracy\": train_accuracy,\n",
    "                \"Validation Loss\": validation_loss,\n",
    "                \"Validation Accuracy\": validation_accuracy\n",
    "            }])], ignore_index=True)\n",
    "    \n",
    "            print(f'Epoch {epoch+1}, Train Loss: {train_loss:.4f}, Train Accuracy: {train_accuracy:.2f}%')\n",
    "            print(f'Epoch {epoch+1}, Val Loss: {validation_loss:.4f}, Val Accuracy: {validation_accuracy:.2f}%')\n",
    "            instances = [\n",
    "                TSP_Instance(np.random.rand(model.city_count, 2)) for _ in tqdm(\n",
    "                    range(nb_eval), desc=\"Instances\", unit=\"instance\", position=0, leave=True\n",
    "                )\n",
    "            ]\n",
    "            greedy = SingleAgentSolver(env, GreedyAgent(ModelEvalActions(model.model)))\n",
    "            solutions = []\n",
    "\n",
    "            for instance in tqdm(instances, desc=\"Solving Instances\", unit=\"instance\", position=0, leave=True):\n",
    "                solution, *_ = greedy.solve(TSP_State(instance, visited=[0]))\n",
    "                dfb = pd.concat([dfb, pd.DataFrame([{\n",
    "                    \"ModelName\" : type(model).__name__,\n",
    "                    \"cities\": model.city_count,\n",
    "                    \"Epoch\": epoch,\n",
    "                    \"iter\": fold,\n",
    "                    \"cost\": solution.cost,                \n",
    "            }]) ])\n",
    "    \n",
    "        # If tqdm was used, close the progress bar\n",
    "        if use_progress_bar:\n",
    "            epoch_range.close()\n",
    "    \n",
    "        # self.unload_model()\n",
    "        return df, dfb;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "29HSyNmfgu8g"
   },
   "outputs": [],
   "source": [
    "## Modelo base\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import DataLoader, TensorDataset, random_split\n",
    "\n",
    "class BaseModel(TrainableModel):\n",
    "\n",
    "    \n",
    "    def load_model(self):\n",
    "        self.model = BaseModel.CustomModel(self.input_dim, self.num_heads, self.head_dim)\n",
    "        \n",
    "    class CustomModel(nn.Module):\n",
    "        def __init__(self, input_dim, num_heads, head_dim, dropout_rate=0.2):\n",
    "            super(BaseModel.CustomModel, self).__init__()\n",
    "            #self.seq_length = seq_length  # Asumiendo una longitud fija de secuencia para simplificar\n",
    "            self.num_heads = num_heads\n",
    "            self.head_dim = head_dim\n",
    "\n",
    "            # Proyección de entrada\n",
    "            self.input_projection = nn.Linear(input_dim, num_heads * head_dim)\n",
    "\n",
    "            # Capa de atención multi-cabeza\n",
    "            self.multihead_attention = nn.MultiheadAttention(embed_dim=num_heads * head_dim,\n",
    "                                                            num_heads=num_heads,\n",
    "                                                            dropout=dropout_rate)\n",
    "\n",
    "            # Capas lineales individuales para cada posición de la secuencia\n",
    "            # Esto es un cambio respecto al código original para aplicar una capa lineal por posición de salida\n",
    "            self.positionwise_linear = nn.Linear(num_heads * head_dim, 1)\n",
    "\n",
    "            # Capa de salida final, después de un flatten, para aplicar Softmax\n",
    "            # Nota: Softmax se aplica después del flatten, por lo tanto no se define aquí como una capa pero sí en el forward\n",
    "\n",
    "        def generate_attention_mask(self, x, padding_value=0):\n",
    "            # Identificar posiciones de padding en x\n",
    "            mask = (x.sum(dim=-1) == padding_value)  # Asumiendo que el padding se puede identificar sumando los valores de la característica y comparando con 0\n",
    "            mask = mask.to(dtype=torch.bool)  # Convierte a bool para usar como máscara\n",
    "            # PyTorch espera una máscara con True y False donde True indica donde aplicar la máscara\n",
    "            return mask\n",
    "\n",
    "\n",
    "        def forward(self, x, seq_lengths=10, return_probabilities=False):\n",
    "            # x: [batch_size, seq_length, input_dim]\n",
    "            x = x.float()\n",
    "\n",
    "            max_len = x.shape[1]\n",
    "\n",
    "            # Generar máscara de atención basada en las longitudes de las secuencias\n",
    "            attn_mask = None\n",
    "\n",
    "            # Aplicar proyección de entrada\n",
    "            x_proj = self.input_projection(x)\n",
    "            x_proj = x_proj.permute(1, 0, 2)  # Reordenar para multihead_attention: [seq_length, batch_size, num_heads*head_dim]\n",
    "\n",
    "\n",
    "            # Aplicar atención multi-cabeza\n",
    "            attn_output, _ = self.multihead_attention(x_proj, x_proj, x_proj, attn_mask=attn_mask)\n",
    "            attn_output = attn_output.permute(1, 0, 2)  # Reordenar de vuelta: [batch_size, seq_length, num_heads*head_dim]\n",
    "\n",
    "            # Aplicar la capa lineal posición por posición\n",
    "            # Usamos una capa lineal que se aplica a cada vector de salida de la atención de forma independiente\n",
    "            positionwise_output = self.positionwise_linear(attn_output)\n",
    "\n",
    "            # Flatten\n",
    "            flat_output = positionwise_output.view(positionwise_output.size(0), -1)  # [batch_size, seq_length]\n",
    "\n",
    "            # Softmax\n",
    "            if return_probabilities:\n",
    "                output = F.softmax(flat_output, dim=-1)\n",
    "                return output\n",
    "            else: #return logits\n",
    "                return flat_output\n",
    "\n",
    "\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "    def load_model(self):\n",
    "        self.model = BaseModel.CustomModel(input_dim=self.input_dim, num_heads=self.num_heads, head_dim=self.head_dim)\n",
    "        self.model.to(self.device)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "cgkPpHf5mihM"
   },
   "outputs": [],
   "source": [
    "class TransformerBlockModel(TrainableModel):\n",
    "\n",
    "  class CustomModel(nn.Module):\n",
    "    class TransformerBlock(nn.Module):\n",
    "        def __init__(self, input_dim, num_heads, head_dim, ff_dim, dropout_rate=0.2):\n",
    "            super(TransformerBlockModel.CustomModel.TransformerBlock, self).__init__()\n",
    "            self.attention = nn.MultiheadAttention(embed_dim=num_heads * head_dim, num_heads=num_heads, dropout=dropout_rate)\n",
    "            self.norm1 = nn.LayerNorm(input_dim)  # LayerNorm based on input_dim\n",
    "            self.ff = nn.Sequential(\n",
    "                nn.Linear(input_dim, ff_dim),\n",
    "                nn.ReLU(),\n",
    "            )\n",
    "            self.norm2 = nn.LayerNorm(input_dim)  # LayerNorm based on input_dim\n",
    "            self.dropout = nn.Dropout(dropout_rate)\n",
    "    \n",
    "        def forward(self, x):\n",
    "            # Attention block\n",
    "            attn_output, _ = self.attention(x, x, x)  # x: (seq_len, batch_size, input_dim)\n",
    "            x = self.norm1(x + self.dropout(attn_output))  # Residual + Norm\n",
    "            \n",
    "            # Feed-forward block\n",
    "            ff_output = self.ff(x)\n",
    "            x = self.norm2(x + self.dropout(ff_output))  # Residual + Norm\n",
    "        \n",
    "            return x\n",
    "\n",
    "    def __init__(self, input_dim, num_heads, head_dim, dropout_rate=0.2):\n",
    "        super(TransformerBlockModel.CustomModel, self).__init__()\n",
    "        #self.seq_length = seq_length  # Asumiendo una longitud fija de secuencia para simplificar\n",
    "        self.num_heads = num_heads\n",
    "        self.head_dim = head_dim\n",
    "        \n",
    "        # Proyección de entrada\n",
    "        self.input_projection = nn.Linear(input_dim, num_heads * head_dim)\n",
    "        \n",
    "        self.attention_blocks = nn.ModuleList([\n",
    "          TransformerBlockModel.CustomModel.TransformerBlock(input_dim=num_heads * head_dim,\n",
    "                                        num_heads=num_heads,\n",
    "                                        head_dim=head_dim,\n",
    "                                        ff_dim=num_heads * head_dim,\n",
    "                                        dropout_rate=dropout_rate)\n",
    "        ])\n",
    "    \n",
    "        # Capas lineales individuales para cada posición de la secuencia\n",
    "        # Esto es un cambio respecto al código original para aplicar una capa lineal por posición de salida\n",
    "        self.positionwise_linear = nn.Linear(num_heads * head_dim, 1)\n",
    "        \n",
    "        # Capa de salida final, después de un flatten, para aplicar Softmax\n",
    "        # Nota: Softmax se aplica después del flatten, por lo tanto no se define aquí como una capa pero sí en el forward\n",
    "\n",
    "    def generate_attention_mask(self, x, padding_value=0):\n",
    "      # Identificar posiciones de padding en x\n",
    "      mask = (x.sum(dim=-1) == padding_value)  # Asumiendo que el padding se puede identificar sumando los valores de la característica y comparando con 0\n",
    "      mask = mask.to(dtype=torch.bool)  # Convierte a bool para usar como máscara\n",
    "      # PyTorch espera una máscara con True y False donde True indica donde aplicar la máscara\n",
    "      return mask\n",
    "    \n",
    "    \n",
    "    def forward(self, x, seq_lengths=10, return_probabilities=False):\n",
    "      # x: [batch_size, seq_length, input_dim]\n",
    "      x = x.float()\n",
    "    \n",
    "      max_len = x.shape[1]\n",
    "    \n",
    "      # Generar máscara de atención basada en las longitudes de las secuencias\n",
    "      attn_mask = None\n",
    "    \n",
    "      # Aplicar proyección de entrada\n",
    "      x_proj = self.input_projection(x)\n",
    "      attn_output = x_proj\n",
    "      x_proj = x_proj.permute(1, 0, 2)  # Reordenar para multihead_attention: [seq_length, batch_size, num_heads*head_dim]\n",
    "    \n",
    "    \n",
    "      # Aplicar atención multi-cabeza\n",
    "      attn_output = self.attention_blocks[0](x_proj)\n",
    "      attn_output = attn_output.permute(1, 0, 2)  # Reordenar de vuelta: [batch_size, seq_length, num_heads*head_dim]\n",
    "    \n",
    "      # Aplicar la capa lineal posición por posición\n",
    "      # Usamos una capa lineal que se aplica a cada vector de salida de la atención de forma independiente\n",
    "      positionwise_output = self.positionwise_linear(attn_output)\n",
    "    \n",
    "      # Flatten\n",
    "      flat_output = positionwise_output.view(positionwise_output.size(0), -1)  # [batch_size, seq_length]\n",
    "    \n",
    "      # Softmax\n",
    "      if return_probabilities:\n",
    "        output = F.softmax(flat_output, dim=-1)\n",
    "        return output\n",
    "      else: #return logits\n",
    "        return flat_output\n",
    "\n",
    "  def load_model(self):\n",
    "    self.model = TransformerBlockModel.CustomModel(input_dim=self.input_dim, num_heads=self.num_heads, head_dim=self.head_dim)\n",
    "    self.model = self.model.to(self.device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "6ekvlK8Qn3HK"
   },
   "outputs": [],
   "source": [
    "## Transformer Block Multicapa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "zRQEnT8Aop_R"
   },
   "outputs": [],
   "source": [
    "class MultilayerTransformerBlockModel(TrainableModel):\n",
    "  class CustomModel(TransformerBlockModel.CustomModel):\n",
    "      def __init__(self, input_dim, num_heads, head_dim, dropout_rate=0.2):\n",
    "          super().__init__(input_dim, num_heads, head_dim, dropout_rate)\n",
    "          self.attention_blocks = nn.ModuleList([TransformerBlockModel.CustomModel.TransformerBlock(input_dim=num_heads * head_dim,\n",
    "                                            num_heads=num_heads,\n",
    "                                            head_dim=head_dim,\n",
    "                                            ff_dim=num_heads * head_dim,\n",
    "                                            dropout_rate=dropout_rate) for _ in range(6)])\n",
    "      def forward(self, x, seq_lengths=10, return_probabilities=False):\n",
    "           x = x.float()\n",
    "\n",
    "           # Projection\n",
    "           x_proj = self.input_projection(x)\n",
    "           # print(x_proj.shape)\n",
    "           x_proj = x_proj.permute(1, 0, 2)  # [seq_length, batch_size, num_heads * head_dim]\n",
    "\n",
    "           # Multi-head attention blocks\n",
    "           for block in self.attention_blocks:\n",
    "               x_proj = block(x_proj)\n",
    "        \n",
    "           x_proj = x_proj.permute(1, 0, 2)  # [batch_size, seq_length, num_heads * head_dim]\n",
    "           # print(x_proj.shape)\n",
    "\n",
    "           # Position-wise linear layer\n",
    "           logits = self.positionwise_linear(x_proj)\n",
    "           # print(logits.shape)\n",
    "\n",
    "           # Flatten\n",
    "           flat_output = logits.view(logits.size(0), -1)  # [batch_size, seq_length]\n",
    "\n",
    "           if return_probabilities:\n",
    "               return F.softmax(flat_output, dim=-1)\n",
    "           return flat_output  # Return logits directly for CrossEntropyLoss\n",
    "\n",
    "  def __init__(self):\n",
    "    super().__init__()\n",
    "  def load_model(self):\n",
    "    self.model = self.CustomModel(input_dim=self.input_dim, num_heads=self.num_heads, head_dim=self.head_dim)\n",
    "    self.model = self.model.to(self.device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 89
    },
    "id": "RIN0IV1Fo61m",
    "outputId": "2cb76ba1-415e-495d-d8f3-ef159cc40637"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WJBJ6roXAQ_C",
    "outputId": "3e0512cf-3f88-40ea-dbf7-c936ecdb6cca"
   },
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# df = pd.DataFrame(columns=[\"Model Name\", \"cities\", \"iter\", \"Epoch\", \"Training Loss\", \"Training Accuracy\", \"Validation Loss\", \"Validation Accuracy\"])\n",
    "# df\n",
    "\n",
    "# dfb = pd.DataFrame(columns=[\"Model Name\", \"cities\", \"iter\", \"avg path cost\"])\n",
    "\n",
    "# import gc\n",
    "# models = [BaseModel(), TransformerBlockModel(), MultilayerTransformerBlockModel()]\n",
    "# # for city_count in [10, 50, 100, 500]:\n",
    "# num_iters=10\n",
    "# eval_count = 50\n",
    "# # for city_count in [50]:\n",
    "\n",
    "# from eda.TSP import TSP_Instance, TSP_Environment, TSP_State, evalConstructiveActions, plot_tour\n",
    "# from eda.agents import SingleAgentSolver, GreedyAgent\n",
    "# import numpy as np\n",
    "\n",
    "\n",
    "# class ModelEvalActions():\n",
    "#   def __init__(self, model):\n",
    "#     self.model=model\n",
    "\n",
    "#   # permite evaluar acctiones de varios estados a la vez\n",
    "#   # para optimizar los cáluclos del modelo\n",
    "#   def __call__(self, states, env):\n",
    "#     single_state = False\n",
    "#     if not isinstance(states, list):\n",
    "#       single_state=True\n",
    "#       states = [states]\n",
    "\n",
    "#     evals = [list() for _ in states]\n",
    "#     vecSeqs=[]; move2idx =[]\n",
    "\n",
    "#     for state in states:\n",
    "#       vecSeq, _, mov2idx = state.state2vecSeq()\n",
    "#       vecSeqs.append(vecSeq)\n",
    "#       move2idx.append(mov2idx)\n",
    "#     device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "#     predictions = self.model(torch.tensor(vecSeqs).to(device), return_probabilities=True)\n",
    "\n",
    "#     for k in range(len(states)):\n",
    "#       state = states[k]\n",
    "#       for action in env.gen_actions(state, \"constructive\"):\n",
    "#           idx = move2idx[k][action[1]] #mapping from move to output index (model)\n",
    "#           evals[k].append((action,predictions[k][idx]))\n",
    "\n",
    "#     if single_state: return evals[0]\n",
    "#     else: return evals\n",
    "\n",
    "# for iter in range(num_iters):\n",
    "#     X = None\n",
    "#     Y = None\n",
    "#     for model in models:\n",
    "#         if X == None and Y == None:\n",
    "#             print(f\"Generando datos iteración i={iter}\")\n",
    "#             X, Y = model.generate_data(use_progress_bar=True)\n",
    "#             X = X.to(model.device)\n",
    "#             Y = Y.to(model.device)\n",
    "        \n",
    "#         name = type(model).__name__\n",
    "#         print(\"Entrenando\", name, \"con n=\", model.city_count)\n",
    "#         trained_model_df, eval_model_df = model.train(X, Y, num_iter=iter, use_progress_bar=True)\n",
    "#         pd.concat([df, trained_model_df])\n",
    "#         # Evaluación post entrenamiento\n",
    "#         print(\"Evaluando modelo: Generando 20 instancias\")\n",
    "#         instances = [\n",
    "#             TSP_Instance(np.random.rand(model.city_count, 2)) for _ in tqdm(\n",
    "#                 range(eval_count), desc=\"Instancias\", unit=\"instance\", position=0, leave=True)\n",
    "#         ]\n",
    "#         greedy = SingleAgentSolver (env,GreedyAgent(ModelEvalActions(model.model)))\n",
    "#         solutions = []\n",
    "#         for instance in tqdm(instances, desc=\"Solving Instances\", unit=\"instance\", position=0, leave=True):\n",
    "#             solution, *_ = greedy.solve(TSP_State(instance, visited=[0]))\n",
    "#             solutions.append(solution.cost)\n",
    "#         model.unload_model()\n",
    "\n",
    "#         solutions_prom = sum(solutions) / len(solutions)\n",
    "#         dfb = pd.concat([dfb, pd.DataFrame([{\n",
    "#             \"Model Name\": type(model).__name__,\n",
    "#             \"iter\": iter,\n",
    "#             \"cities\": model.city_count,\n",
    "#             \"avg path cost\": solutions_prom\n",
    "#         }])])\n",
    "        \n",
    "#     del X\n",
    "#     del Y\n",
    "#     X = None\n",
    "#     Y = None\n",
    "\n",
    "\n",
    "# df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "hZDgyCWJGWrY"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m df\u001b[38;5;241m.\u001b[39mto_csv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mout2.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "df.to_csv(\"out2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfb.groupby([\"Model Name\", \"cities\"]).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.DataFrame(columns=[\"model_name\", \"iter\", \"epoch\", \"tr_loss\", \"tr_acc\", \"val_loss\", \"val_acc\"])\n",
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_df = pd.DataFrame(columns=[\"model_name\", \"iter\", \"epoch\", \"cost\"])\n",
    "eval_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "from eda.TSP import TSP_Instance, TSP_Environment, TSP_State, evalConstructiveActions, plot_tour\n",
    "from eda.agents import SingleAgentSolver, GreedyAgent\n",
    "nb_cities = 50\n",
    "nb_samples=20000\n",
    "nb_eval = 50\n",
    "k_folds=10\n",
    "iter=0\n",
    "models = [#BaseModel(), TransformerBlockModel(),\n",
    "    MultilayerTransformerBlockModel()]\n",
    "class ModelEvalActions():\n",
    "  def __init__(self, model):\n",
    "    self.model=model\n",
    "\n",
    "  # permite evaluar acctiones de varios estados a la vez\n",
    "  # para optimizar los cáluclos del modelo\n",
    "  def __call__(self, states, env):\n",
    "    single_state = False\n",
    "    if not isinstance(states, list):\n",
    "      single_state=True\n",
    "      states = [states]\n",
    "\n",
    "    evals = [list() for _ in states]\n",
    "    vecSeqs=[]; move2idx =[]\n",
    "\n",
    "    for state in states:\n",
    "      vecSeq, _, mov2idx = state.state2vecSeq()\n",
    "      vecSeqs.append(vecSeq)\n",
    "      move2idx.append(mov2idx)\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    predictions = self.model(torch.tensor(vecSeqs).to(device), return_probabilities=True)\n",
    "\n",
    "    for k in range(len(states)):\n",
    "      state = states[k]\n",
    "      for action in env.gen_actions(state, \"constructive\"):\n",
    "          idx = move2idx[k][action[1]] #mapping from move to output index (model)\n",
    "          evals[k].append((action,predictions[k][idx]))\n",
    "\n",
    "    if single_state: return evals[0]\n",
    "    else: return evals\n",
    "\n",
    "\n",
    "for model in models:\n",
    "        print(f\"Iteration {iter}: Preparing dataset\")\n",
    "\n",
    "        # Generate data once per iteration\n",
    "        print(f\"Generating data for iteration {iter}\")\n",
    "        X, Y = model.generate_data(use_progress_bar=True)\n",
    "        X = X.to(model.device)\n",
    "        Y = Y.to(model.device)\n",
    "\n",
    "        kfold = KFold(n_splits=k_folds, shuffle=True, random_state=iter)\n",
    "        fold = 0\n",
    "\n",
    "        for train_idx, val_idx in kfold.split(X):\n",
    "            fold += 1\n",
    "\n",
    "            print(f\"Training {type(model).__name__} on fold {fold}\")\n",
    "\n",
    "            # Split data into train and validation sets\n",
    "            X_train, X_val = X[train_idx], X[val_idx]\n",
    "            Y_train, Y_val = Y[train_idx], Y[val_idx]\n",
    "\n",
    "            model.load_model()\n",
    "            # Train the model\n",
    "            trained_model_df, eval_model_df = model.train(X_train, Y_train, X_val, Y_val, use_progress_bar=False, num_iter = fold +1)\n",
    "                        # Log training metrics\n",
    "            for _, row in trained_model_df.iterrows():\n",
    "                train_df = pd.concat([train_df, pd.DataFrame([{\n",
    "                    \"model_name\": type(model).__name__,\n",
    "                    \"iter\": row['iter'],\n",
    "                    \"epoch\": row[\"Epoch\"],\n",
    "                    \"tr_loss\": row[\"Training Loss\"],\n",
    "                    \"tr_acc\": row[\"Training Accuracy\"],\n",
    "                    \"val_loss\": row[\"Validation Loss\"],\n",
    "                    \"val_acc\": row[\"Validation Accuracy\"]\n",
    "                }])])\n",
    "            for _, row in eval_model_df.iterrows():\n",
    "                eval_df = pd.concat([eval_df, pd.DataFrame([{\n",
    "                    \"model_name\": type(model).__name__,\n",
    "                    \"iter\": row['iter'],\n",
    "                    \"epoch\": row[\"Epoch\"],\n",
    "                    \"cost\": row['cost']\n",
    "                }])])\n",
    "            model.unload_model()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ex_traindf = train_df.reset_index().drop('index', axis=1)\n",
    "ex_evaldf = eval_df.reset_index().drop('index', axis=1)\n",
    "ex_evaldf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ex_traindf.to_csv(\"train_df.csv\")\n",
    "ex_evaldf.to_csv(\"eval_df.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
