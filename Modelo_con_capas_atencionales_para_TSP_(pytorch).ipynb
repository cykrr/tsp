{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7IP57jvFo4Wh",
    "outputId": "c0bc6b35-82b2-4511-d8ca-2df2f87cd843"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m26.7/26.7 MB\u001b[0m \u001b[31m21.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m133.7/133.7 kB\u001b[0m \u001b[31m14.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m309.2/309.2 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "cudf-cu12 24.4.1 requires protobuf<5,>=3.20, but you have protobuf 5.27.0 which is incompatible.\n",
      "google-ai-generativelanguage 0.6.4 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 5.27.0 which is incompatible.\n",
      "google-api-core 2.11.1 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0.dev0,>=3.19.5, but you have protobuf 5.27.0 which is incompatible.\n",
      "google-cloud-aiplatform 1.52.0 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 5.27.0 which is incompatible.\n",
      "google-cloud-bigquery-connection 1.12.1 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 5.27.0 which is incompatible.\n",
      "google-cloud-bigquery-storage 2.25.0 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 5.27.0 which is incompatible.\n",
      "google-cloud-datastore 2.15.2 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 5.27.0 which is incompatible.\n",
      "google-cloud-firestore 2.11.1 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 5.27.0 which is incompatible.\n",
      "google-cloud-functions 1.13.3 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 5.27.0 which is incompatible.\n",
      "google-cloud-iam 2.15.0 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 5.27.0 which is incompatible.\n",
      "google-cloud-language 2.13.3 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 5.27.0 which is incompatible.\n",
      "google-cloud-resource-manager 1.12.3 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 5.27.0 which is incompatible.\n",
      "google-cloud-translate 3.11.3 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 5.27.0 which is incompatible.\n",
      "googleapis-common-protos 1.63.0 requires protobuf!=3.20.0,!=3.20.1,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0.dev0,>=3.19.5, but you have protobuf 5.27.0 which is incompatible.\n",
      "grpc-google-iam-v1 0.13.0 requires protobuf!=3.20.0,!=3.20.1,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 5.27.0 which is incompatible.\n",
      "proto-plus 1.23.0 requires protobuf<5.0.0dev,>=3.19.0, but you have protobuf 5.27.0 which is incompatible.\n",
      "tensorflow 2.15.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3, but you have protobuf 5.27.0 which is incompatible.\n",
      "tensorflow-metadata 1.15.0 requires protobuf<4.21,>=3.20.3; python_version < \"3.11\", but you have protobuf 5.27.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mCloning into 'eda'...\n",
      "remote: Enumerating objects: 65, done.\u001b[K\n",
      "remote: Counting objects: 100% (7/7), done.\u001b[K\n",
      "remote: Compressing objects: 100% (7/7), done.\u001b[K\n",
      "remote: Total 65 (delta 1), reused 0 (delta 0), pack-reused 58\u001b[K\n",
      "Receiving objects: 100% (65/65), 119.23 KiB | 961.00 KiB/s, done.\n",
      "Resolving deltas: 100% (31/31), done.\n"
     ]
    }
   ],
   "source": [
    "!pip install ortools -q\n",
    "# download codes\n",
    "!git clone https://github.com/rilianx/eda.git"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZmKUpDeVLUU3"
   },
   "source": [
    "## Creación del Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "WuJ9PC68ReLw"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CustomModel(\n",
      "  (input_projection): Linear(in_features=6, out_features=640, bias=True)\n",
      "  (multihead_attention): MultiheadAttention(\n",
      "    (out_proj): NonDynamicallyQuantizableLinear(in_features=640, out_features=640, bias=True)\n",
      "  )\n",
      "  (positionwise_linear): Linear(in_features=640, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class CustomModel(nn.Module):\n",
    "    def __init__(self, input_dim, num_heads, head_dim, dropout_rate=0.2):\n",
    "        super(CustomModel, self).__init__()\n",
    "        #self.seq_length = seq_length  # Asumiendo una longitud fija de secuencia para simplificar\n",
    "        self.num_heads = num_heads\n",
    "        self.head_dim = head_dim\n",
    "\n",
    "        # Proyección de entrada\n",
    "        self.input_projection = nn.Linear(input_dim, num_heads * head_dim)\n",
    "\n",
    "        # Capa de atención multi-cabeza\n",
    "        self.multihead_attention = nn.MultiheadAttention(embed_dim=num_heads * head_dim,\n",
    "                                                         num_heads=num_heads,\n",
    "                                                         dropout=dropout_rate)\n",
    "\n",
    "        # Capas lineales individuales para cada posición de la secuencia\n",
    "        # Esto es un cambio respecto al código original para aplicar una capa lineal por posición de salida\n",
    "        self.positionwise_linear = nn.Linear(num_heads * head_dim, 1)\n",
    "\n",
    "        # Capa de salida final, después de un flatten, para aplicar Softmax\n",
    "        # Nota: Softmax se aplica después del flatten, por lo tanto no se define aquí como una capa pero sí en el forward\n",
    "\n",
    "    def generate_attention_mask(self, x, padding_value=0):\n",
    "        # Identificar posiciones de padding en x\n",
    "        mask = (x.sum(dim=-1) == padding_value)  # Asumiendo que el padding se puede identificar sumando los valores de la característica y comparando con 0\n",
    "        mask = mask.to(dtype=torch.bool)  # Convierte a bool para usar como máscara\n",
    "        # PyTorch espera una máscara con True y False donde True indica donde aplicar la máscara\n",
    "        return mask\n",
    "\n",
    "\n",
    "    def forward(self, x, seq_lengths=10, return_probabilities=False):\n",
    "        # x: [batch_size, seq_length, input_dim]\n",
    "        x = x.float()\n",
    "\n",
    "        max_len = x.shape[1]\n",
    "\n",
    "        # Generar máscara de atención basada en las longitudes de las secuencias\n",
    "        attn_mask = None\n",
    "\n",
    "        # Aplicar proyección de entrada\n",
    "        x_proj = self.input_projection(x)\n",
    "        x_proj = x_proj.permute(1, 0, 2)  # Reordenar para multihead_attention: [seq_length, batch_size, num_heads*head_dim]\n",
    "\n",
    "\n",
    "        # Aplicar atención multi-cabeza\n",
    "        attn_output, _ = self.multihead_attention(x_proj, x_proj, x_proj, attn_mask=attn_mask)\n",
    "        attn_output = attn_output.permute(1, 0, 2)  # Reordenar de vuelta: [batch_size, seq_length, num_heads*head_dim]\n",
    "\n",
    "        # Aplicar la capa lineal posición por posición\n",
    "        # Usamos una capa lineal que se aplica a cada vector de salida de la atención de forma independiente\n",
    "        positionwise_output = self.positionwise_linear(attn_output)\n",
    "\n",
    "        # Flatten\n",
    "        flat_output = positionwise_output.view(positionwise_output.size(0), -1)  # [batch_size, seq_length]\n",
    "\n",
    "        # Softmax\n",
    "        if return_probabilities:\n",
    "          output = F.softmax(flat_output, dim=-1)\n",
    "          return output\n",
    "        else: #return logits\n",
    "          return flat_output\n",
    "\n",
    "\n",
    "\n",
    "# Parámetros del modelo\n",
    "input_dim = 6  # Dimensión de la entrada\n",
    "num_heads = 10  # Número de cabezas en la atención multi-cabeza\n",
    "head_dim = 64  # Dimensión de cada cabeza\n",
    "\n",
    "\n",
    "# Crear el modelo\n",
    "model = CustomModel(input_dim=input_dim, num_heads=num_heads, head_dim=head_dim)\n",
    "\n",
    "# Información del modelo (Opcional)\n",
    "print(model)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YDvnwDjCrOmY"
   },
   "source": [
    "## Generación de datos usando **Algoritmo clásico**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "HE3Hy8D98N8M"
   },
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "import random\n",
    "import math\n",
    "\n",
    "def distance(punto1, punto2):\n",
    "    return math.sqrt((punto1[0] - punto2[0])**2 + (punto1[1] - punto2[1])**2)\n",
    "\n",
    "# función para transformar un estado tsp en una secuencia de vectores\n",
    "# para el modelo basado en capas de atención\n",
    "def state2vecSeq(self):\n",
    "    # creamos dos diccionarios para mantenre un mapeo de los\n",
    "    # movimientos con los índices de la secuencia del modelo de aprendizaje\n",
    "\n",
    "    city_locations = self.inst_info.city_locations\n",
    "\n",
    "    idx2move = dict()\n",
    "    move2idx = dict()\n",
    "    origin = city_locations[self.visited[-1]]\n",
    "    destination = city_locations[self.visited[0]]\n",
    "\n",
    "    origin_dist = 0.0\n",
    "    dest_dist = distance(origin, destination)\n",
    "\n",
    "    seq = [list(origin) + [1,0] + [origin_dist, dest_dist], # Última ciudad visitada (origen)\n",
    "           list(destination) + [0, 1] + [dest_dist, 0.0]]  # Ciudad final\n",
    "\n",
    "    idx2move[0] = None\n",
    "    idx2move[1] = (\"constructive\", self.visited[0])\n",
    "    move2idx[self.visited[0]] = 1\n",
    "\n",
    "    idx = 2\n",
    "    for i in self.not_visited:\n",
    "        point = list(city_locations[i])\n",
    "        origin_dist = distance( point, origin)\n",
    "        dest_dist = distance( point, destination)\n",
    "        city_vector = point + [0, 0] + [origin_dist, dest_dist] # Otras ciudades\n",
    "\n",
    "        seq.append(city_vector)\n",
    "        idx2move[idx] = (\"constructive\", i)\n",
    "        move2idx[i] = idx\n",
    "        idx += 1\n",
    "\n",
    "    return seq, idx2move, move2idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Q7UgboEfrQNN",
    "outputId": "c2014eb3-7f28-48ce-e069-944723bb1862"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[0.1851, 0.5419, 1.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.1851, 0.5419, 0.0000, 1.0000, 0.0000, 0.0000],\n",
       "          [0.8729, 0.7322, 0.0000, 0.0000, 0.7137, 0.7137],\n",
       "          [0.8066, 0.6588, 0.0000, 0.0000, 0.6323, 0.6323],\n",
       "          [0.6923, 0.8492, 0.0000, 0.0000, 0.5930, 0.5930],\n",
       "          [0.2497, 0.4894, 0.0000, 0.0000, 0.0832, 0.0832]],\n",
       " \n",
       "         [[0.2497, 0.4894, 1.0000, 0.0000, 0.0000, 0.0832],\n",
       "          [0.1851, 0.5419, 0.0000, 1.0000, 0.0832, 0.0000],\n",
       "          [0.8729, 0.7322, 0.0000, 0.0000, 0.6689, 0.7137],\n",
       "          [0.8066, 0.6588, 0.0000, 0.0000, 0.5821, 0.6323],\n",
       "          [0.6923, 0.8492, 0.0000, 0.0000, 0.5704, 0.5930],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
       " \n",
       "         [[0.8066, 0.6588, 1.0000, 0.0000, 0.0000, 0.6323],\n",
       "          [0.1851, 0.5419, 0.0000, 1.0000, 0.6323, 0.0000],\n",
       "          [0.8729, 0.7322, 0.0000, 0.0000, 0.0990, 0.7137],\n",
       "          [0.6923, 0.8492, 0.0000, 0.0000, 0.2221, 0.5930],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
       " \n",
       "         [[0.8729, 0.7322, 1.0000, 0.0000, 0.0000, 0.7137],\n",
       "          [0.1851, 0.5419, 0.0000, 1.0000, 0.7137, 0.0000],\n",
       "          [0.6923, 0.8492, 0.0000, 0.0000, 0.2152, 0.5930],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]],\n",
       "        dtype=torch.float64),\n",
       " tensor([[0, 0, 0, 0, 0, 1],\n",
       "         [0, 0, 0, 1, 0, 0],\n",
       "         [0, 0, 1, 0, 0, 0],\n",
       "         [0, 0, 1, 0, 0, 0]]))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from torch.nn.functional import one_hot\n",
    "from eda.TSP import TSP_Instance, TSP_Environment, TSP_State\n",
    "from eda.solveTSP_v2 import solve\n",
    "env = TSP_Environment\n",
    "\n",
    "def generate_data(max_cities=20, nb_sample=100):\n",
    "    X = []  # Lista para almacenar las secuencias de entrada\n",
    "    Y = []  # Lista para almacenar las etiquetas objetivo (las siguientes ciudades a visitar)\n",
    "    seq_len = max_cities + 1  # Longitud de la secuencia, ajustada para incluir una ciudad extra\n",
    "\n",
    "    # Bucle para generar datos hasta alcanzar el número deseado de muestras\n",
    "    while True:\n",
    "        # 1. Generamos instancia aleatoria\n",
    "        n_cities = max_cities\n",
    "        dim = 2  # Dimensión para las coordenadas de la ciudad (2D: x, y)\n",
    "        city_points = np.random.rand(n_cities, dim)  # Generar puntos aleatorios para las ciudades\n",
    "        inst_info = TSP_Instance(city_points)\n",
    "\n",
    "        # 2. Resolvemos TSP usando algoritmo tradicional\n",
    "        solution = solve(city_points)  # Resolver el TSP y obtener un estado final\n",
    "\n",
    "        # 3. Iteramos sobre los movimientos de la solución final para generar varias muestras:\n",
    "        # estado (X) -> movimiento (Y)\n",
    "        current_state = TSP_State (inst_info)\n",
    "        env.state_transition(current_state, (\"constructive\",solution.visited[0]))\n",
    "        samples_per_sol = max_cities-1  # Número máximo de muestras por solución\n",
    "        for move in [(\"constructive\", city) for city in solution.visited[1:]]:\n",
    "            seq, _, move2idx = state2vecSeq(current_state)  # Convertir el estado actual a secuencia vectorizada\n",
    "\n",
    "            X.append(torch.tensor(seq))  # Añadir la secuencia a X\n",
    "            Y.append(one_hot(torch.tensor(move2idx[move[1]]), num_classes=seq_len))\n",
    "            #Y.append(to_categorical(move2idx[move[1]], num_classes=seq_len))  # Añadir el movimiento como categoría a Y\n",
    "\n",
    "            env.state_transition(current_state, move)  # Hacer la transición al siguiente estado\n",
    "\n",
    "            # Condiciones de parada basadas en el número de ciudades visitadas/no visitadas o muestras generadas\n",
    "            if len(current_state.visited) > samples_per_sol or len(X) >= nb_sample:\n",
    "                break\n",
    "\n",
    "        # Romper el bucle externo si se ha alcanzado el número deseado de muestras\n",
    "        if len(X) >= nb_sample:\n",
    "            break\n",
    "\n",
    "    X_padded = torch.nn.utils.rnn.pad_sequence(X, batch_first=True)\n",
    "\n",
    "    return X_padded, torch.stack(Y)\n",
    "\n",
    "generate_data(5,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QI0a7f0Cz7to",
    "outputId": "d1548faa-5eb0-496c-ceec-4c9cf982b95f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([20000, 11, 6]) torch.Size([20000, 11])\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X,Y=generate_data(max_cities=10, nb_sample=20000)\n",
    "print(X.shape,Y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YNX7U1g4RUMg"
   },
   "source": [
    "## Entrenamiento del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "q2MZUy9CXKMa",
    "outputId": "f9ca57c6-1480-4af9-8ff7-4250e12623f9"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\krr\\AppData\\Local\\Temp\\ipykernel_67940\\2078920795.py:61: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df = pd.concat([df, pd.DataFrame([{\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Train Loss: 0.5560, Train Accuracy: 80.11%\n",
      "Epoch 1, Val Loss: 0.3852, Val Accuracy: 87.31%\n",
      "Epoch 2, Train Loss: 0.4516, Train Accuracy: 83.78%\n",
      "Epoch 2, Val Loss: 0.3824, Val Accuracy: 87.87%\n",
      "Epoch 3, Train Loss: 0.4321, Train Accuracy: 85.03%\n",
      "Epoch 3, Val Loss: 0.3621, Val Accuracy: 87.96%\n",
      "Epoch 4, Train Loss: 0.4198, Train Accuracy: 85.27%\n",
      "Epoch 4, Val Loss: 0.3623, Val Accuracy: 87.87%\n",
      "Epoch 5, Train Loss: 0.4104, Train Accuracy: 85.25%\n",
      "Epoch 5, Val Loss: 0.3553, Val Accuracy: 87.98%\n",
      "Epoch 1, Train Loss: 0.4090, Train Accuracy: 85.48%\n",
      "Epoch 1, Val Loss: 0.3599, Val Accuracy: 88.11%\n",
      "Epoch 2, Train Loss: 0.4055, Train Accuracy: 85.52%\n",
      "Epoch 2, Val Loss: 0.3581, Val Accuracy: 88.01%\n",
      "Epoch 3, Train Loss: 0.4029, Train Accuracy: 85.39%\n",
      "Epoch 3, Val Loss: 0.3580, Val Accuracy: 88.69%\n",
      "Epoch 4, Train Loss: 0.3897, Train Accuracy: 86.11%\n",
      "Epoch 4, Val Loss: 0.3415, Val Accuracy: 88.54%\n",
      "Epoch 5, Train Loss: 0.3864, Train Accuracy: 86.30%\n",
      "Epoch 5, Val Loss: 0.3468, Val Accuracy: 88.38%\n",
      "Epoch 1, Train Loss: 0.3903, Train Accuracy: 86.22%\n",
      "Epoch 1, Val Loss: 0.3370, Val Accuracy: 89.07%\n",
      "Epoch 2, Train Loss: 0.3840, Train Accuracy: 86.43%\n",
      "Epoch 2, Val Loss: 0.3441, Val Accuracy: 88.82%\n",
      "Epoch 3, Train Loss: 0.3946, Train Accuracy: 86.30%\n",
      "Epoch 3, Val Loss: 0.3332, Val Accuracy: 88.95%\n",
      "Epoch 4, Train Loss: 0.3859, Train Accuracy: 86.06%\n",
      "Epoch 4, Val Loss: 0.3475, Val Accuracy: 88.64%\n",
      "Epoch 5, Train Loss: 0.3848, Train Accuracy: 86.16%\n",
      "Epoch 5, Val Loss: 0.3350, Val Accuracy: 88.76%\n",
      "Epoch 1, Train Loss: 0.3735, Train Accuracy: 86.51%\n",
      "Epoch 1, Val Loss: 0.3225, Val Accuracy: 89.12%\n",
      "Epoch 2, Train Loss: 0.3718, Train Accuracy: 86.82%\n",
      "Epoch 2, Val Loss: 0.3326, Val Accuracy: 88.96%\n",
      "Epoch 3, Train Loss: 0.3777, Train Accuracy: 86.77%\n",
      "Epoch 3, Val Loss: 0.3280, Val Accuracy: 88.99%\n",
      "Epoch 4, Train Loss: 0.3679, Train Accuracy: 86.68%\n",
      "Epoch 4, Val Loss: 0.3291, Val Accuracy: 89.06%\n",
      "Epoch 5, Train Loss: 0.3742, Train Accuracy: 86.76%\n",
      "Epoch 5, Val Loss: 0.3323, Val Accuracy: 88.72%\n",
      "Epoch 1, Train Loss: 0.3675, Train Accuracy: 86.78%\n",
      "Epoch 1, Val Loss: 0.3422, Val Accuracy: 88.87%\n",
      "Epoch 2, Train Loss: 0.3646, Train Accuracy: 86.97%\n",
      "Epoch 2, Val Loss: 0.3234, Val Accuracy: 88.91%\n",
      "Epoch 3, Train Loss: 0.3642, Train Accuracy: 86.98%\n",
      "Epoch 3, Val Loss: 0.3286, Val Accuracy: 89.17%\n",
      "Epoch 4, Train Loss: 0.3641, Train Accuracy: 87.06%\n",
      "Epoch 4, Val Loss: 0.3309, Val Accuracy: 88.95%\n",
      "Epoch 5, Train Loss: 0.3672, Train Accuracy: 86.82%\n",
      "Epoch 5, Val Loss: 0.3285, Val Accuracy: 88.84%\n",
      "Epoch 1, Train Loss: 0.3603, Train Accuracy: 87.46%\n",
      "Epoch 1, Val Loss: 0.3266, Val Accuracy: 89.08%\n",
      "Epoch 2, Train Loss: 0.3614, Train Accuracy: 87.11%\n",
      "Epoch 2, Val Loss: 0.3386, Val Accuracy: 88.72%\n",
      "Epoch 3, Train Loss: 0.3619, Train Accuracy: 86.96%\n",
      "Epoch 3, Val Loss: 0.3200, Val Accuracy: 89.23%\n",
      "Epoch 4, Train Loss: 0.3610, Train Accuracy: 87.22%\n",
      "Epoch 4, Val Loss: 0.3191, Val Accuracy: 89.20%\n",
      "Epoch 5, Train Loss: 0.3596, Train Accuracy: 87.18%\n",
      "Epoch 5, Val Loss: 0.3159, Val Accuracy: 89.66%\n",
      "Epoch 1, Train Loss: 0.3578, Train Accuracy: 87.25%\n",
      "Epoch 1, Val Loss: 0.3175, Val Accuracy: 89.44%\n",
      "Epoch 2, Train Loss: 0.3592, Train Accuracy: 87.20%\n",
      "Epoch 2, Val Loss: 0.3249, Val Accuracy: 88.82%\n",
      "Epoch 3, Train Loss: 0.3574, Train Accuracy: 87.47%\n",
      "Epoch 3, Val Loss: 0.3184, Val Accuracy: 89.18%\n",
      "Epoch 4, Train Loss: 0.3604, Train Accuracy: 87.13%\n",
      "Epoch 4, Val Loss: 0.3203, Val Accuracy: 88.83%\n",
      "Epoch 5, Train Loss: 0.3565, Train Accuracy: 87.54%\n",
      "Epoch 5, Val Loss: 0.3585, Val Accuracy: 88.87%\n",
      "Epoch 1, Train Loss: 0.3582, Train Accuracy: 87.44%\n",
      "Epoch 1, Val Loss: 0.3173, Val Accuracy: 89.38%\n",
      "Epoch 2, Train Loss: 0.3579, Train Accuracy: 87.32%\n",
      "Epoch 2, Val Loss: 0.3317, Val Accuracy: 89.00%\n",
      "Epoch 3, Train Loss: 0.3547, Train Accuracy: 87.41%\n",
      "Epoch 3, Val Loss: 0.3094, Val Accuracy: 89.59%\n",
      "Epoch 4, Train Loss: 0.3562, Train Accuracy: 87.23%\n",
      "Epoch 4, Val Loss: 0.3233, Val Accuracy: 88.94%\n",
      "Epoch 5, Train Loss: 0.3531, Train Accuracy: 87.23%\n",
      "Epoch 5, Val Loss: 0.3058, Val Accuracy: 89.68%\n",
      "Epoch 1, Train Loss: 0.3542, Train Accuracy: 87.64%\n",
      "Epoch 1, Val Loss: 0.3166, Val Accuracy: 89.50%\n",
      "Epoch 2, Train Loss: 0.3707, Train Accuracy: 86.63%\n",
      "Epoch 2, Val Loss: 0.3193, Val Accuracy: 88.99%\n",
      "Epoch 3, Train Loss: 0.3615, Train Accuracy: 87.05%\n",
      "Epoch 3, Val Loss: 0.3208, Val Accuracy: 89.38%\n",
      "Epoch 4, Train Loss: 0.3484, Train Accuracy: 87.70%\n",
      "Epoch 4, Val Loss: 0.3204, Val Accuracy: 89.05%\n",
      "Epoch 5, Train Loss: 0.3483, Train Accuracy: 87.76%\n",
      "Epoch 5, Val Loss: 0.3289, Val Accuracy: 88.89%\n",
      "Epoch 1, Train Loss: 0.3535, Train Accuracy: 87.55%\n",
      "Epoch 1, Val Loss: 0.3170, Val Accuracy: 89.22%\n",
      "Epoch 2, Train Loss: 0.3558, Train Accuracy: 87.34%\n",
      "Epoch 2, Val Loss: 0.3066, Val Accuracy: 89.66%\n",
      "Epoch 3, Train Loss: 0.3501, Train Accuracy: 87.82%\n",
      "Epoch 3, Val Loss: 0.3232, Val Accuracy: 89.40%\n",
      "Epoch 4, Train Loss: 0.3489, Train Accuracy: 87.24%\n",
      "Epoch 4, Val Loss: 0.3146, Val Accuracy: 89.52%\n",
      "Epoch 5, Train Loss: 0.3456, Train Accuracy: 87.45%\n",
      "Epoch 5, Val Loss: 0.3179, Val Accuracy: 89.20%\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import DataLoader, TensorDataset, random_split\n",
    "import pandas as pd\n",
    "\n",
    "# Asumiendo que X_padded y Y_stacked ya están definidos y son tensores de PyTorch\n",
    "dataset = TensorDataset(X, Y)\n",
    "\n",
    "# Dividir el dataset en entrenamiento y prueba}\n",
    "train_size = int(0.5 * len(dataset))\n",
    "test_size = len(dataset) - train_size\n",
    "train_dataset, test_dataset = random_split(dataset, [train_size, test_size])\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=128, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=128, shuffle=False)\n",
    "\n",
    "# Definir el modelo, la función de pérdida y el optimizador\n",
    "loss_function = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters())\n",
    "\n",
    "# Ciclo de entrenamiento\n",
    "epochs = 5\n",
    "# Initialize the DataFrame to store training results\n",
    "df = pd.DataFrame(columns=[\"cities\", \"iter\", \"Epoch\",\n",
    "                           \"Training Loss\", \"Training Accuracy\",\n",
    "                           \"Validation Loss\", \"Validation Accuracy\"])\n",
    "for num_iter in range(10):\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        correct = 0; total = 0\n",
    "        for X_batch, y_batch in train_loader:\n",
    "            optimizer.zero_grad()  # Limpia los gradientes\n",
    "            outputs = model(X_batch)  # Obtenemos logits\n",
    "            loss = loss_function(outputs, y_batch.argmax(dim=1))  # Calcular la pérdida\n",
    "            loss.backward()  # Backward pass\n",
    "            optimizer.step()  # Actualizar parámetros\n",
    "            train_loss += loss.item() * X_batch.size(0)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += y_batch.size(0)\n",
    "            correct += (predicted == y_batch.argmax(dim=1)).sum().item()\n",
    "\n",
    "    \n",
    "        train_loss /= len(train_loader.dataset)\n",
    "        train_accuracy = 100 * correct / total\n",
    "    \n",
    "        # Validación\n",
    "        model.eval()\n",
    "        validation_loss = 0\n",
    "        correct = 0; total = 0\n",
    "        with torch.no_grad():\n",
    "            for X_batch, y_batch in test_loader:\n",
    "                outputs = model(X_batch)\n",
    "                loss = loss_function(outputs, y_batch.argmax(dim=1))\n",
    "                validation_loss += loss.item() * X_batch.size(0)\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                total += y_batch.size(0)\n",
    "                correct += (predicted == y_batch.argmax(dim=1)).sum().item()\n",
    "        validation_loss /= len(test_loader.dataset)\n",
    "        validation_accuracy = 100 * correct / total\n",
    "        df = pd.concat([df, pd.DataFrame([{\n",
    "            \"cities\": 50,\n",
    "            \"iter\": num_iter,\n",
    "            \"Epoch\": epoch + 1,\n",
    "            \"Training Loss\": train_loss,\n",
    "            \"Training Accuracy\": train_accuracy,\n",
    "            \"Validation Loss\": validation_loss,\n",
    "            \"Validation Accuracy\": validation_accuracy\n",
    "        }])], ignore_index=True)\n",
    "    \n",
    "        print(f'Epoch {epoch+1}, Train Loss: {train_loss:.4f}, Train Accuracy: {train_accuracy:.2f}%')\n",
    "        print(f'Epoch {epoch+1}, Val Loss: {validation_loss:.4f}, Val Accuracy: {validation_accuracy:.2f}%')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aD-kS8FhMSxt"
   },
   "source": [
    "## Validación del modelo.\n",
    "Se utiliza como función de evaluación de movimientos dentro de algoritmo constructivo Greedy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "cs7Bc7k64KG4",
    "outputId": "aecc41c5-0005-48f1-b8d6-e517adb6d5ae"
   },
   "outputs": [],
   "source": [
    "from eda.TSP import TSP_Instance, TSP_Environment, TSP_State, evalConstructiveActions, plot_tour\n",
    "from eda.agents import SingleAgentSolver, GreedyAgent\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "#with open('tsp_model.pkl', 'rb') as archivo:\n",
    "#    model = pickle.load(archivo)\n",
    "\n",
    "class ModelEvalActions():\n",
    "  def __init__(self, model):\n",
    "    self.model=model\n",
    "\n",
    "  # permite evaluar acctiones de varios estados a la vez\n",
    "  # para optimizar los cáluclos del modelo\n",
    "  def __call__(self, states, env):\n",
    "    single_state = False\n",
    "    if not isinstance(states, list):\n",
    "      single_state=True\n",
    "      states = [states]\n",
    "\n",
    "    evals = [list() for _ in states]\n",
    "    vecSeqs=[]; move2idx =[]\n",
    "\n",
    "    for state in states:\n",
    "      vecSeq, _, mov2idx = state.state2vecSeq()\n",
    "      vecSeqs.append(vecSeq)\n",
    "      move2idx.append(mov2idx)\n",
    "\n",
    "    predictions = self.model(torch.tensor(vecSeqs), return_probabilities=True)\n",
    "\n",
    "    for k in range(len(states)):\n",
    "      state = states[k]\n",
    "      for action in env.gen_actions(state, \"constructive\"):\n",
    "          idx = move2idx[k][action[1]] #mapping from move to output index (model)\n",
    "          evals[k].append((action,predictions[k][idx]))\n",
    "\n",
    "    if single_state: return evals[0]\n",
    "    else: return evals\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "# creamos un problema con 50 ciudades en un plano 2D\n",
    "cities  = np.random.rand(500, 2)\n",
    "inst_info = TSP_Instance(cities)\n",
    "\n",
    "# referenciamos nuestro ambiente con las \"reglas del juego\"\n",
    "env = TSP_Environment\n",
    "# creamos nuestro agente\n",
    "greedy = SingleAgentSolver (env,GreedyAgent(ModelEvalActions(model)))\n",
    "solution, *_ = greedy.solve(TSP_State (inst_info, visited=[0]))\n",
    "print(\"Model solution:\\n\", solution)\n",
    "plot_tour(cities, solution.visited)\n",
    "\n",
    "\n",
    "greedy2 = SingleAgentSolver (env,GreedyAgent(evalConstructiveActions))\n",
    "solution, *_ = greedy2.solve(TSP_State (inst_info, visited=[0]))\n",
    "print(\"Greedy solution:\\n\", solution)\n",
    "plot_tour(cities, solution.visited)\n",
    "\n",
    "solution = solve(cities)\n",
    "print (\"OR-Tools:\",solution.cost)\n",
    "plot_tour(cities, solution.visited)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MlkZa2J5XHSN"
   },
   "source": [
    "### Múltiples ejecuciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 565
    },
    "id": "jwkGPpCAXmbG",
    "outputId": "526a688a-a608-4413-f44a-d46be29d7353"
   },
   "outputs": [],
   "source": [
    "from eda.agents import StochasticGreedyAgent\n",
    "\n",
    "greedy = SingleAgentSolver (env,StochasticGreedyAgent(ModelEvalActions(model), steepness=50))\n",
    "solutions, *_ = greedy.multistate_solve([deepcopy(TSP_State (inst_info, visited=[0])) for _ in range(10)])\n",
    "\n",
    "print([s.cost for s in solutions])\n",
    "\n",
    "best_sol = min(solutions, key=lambda solution: solution.cost)\n",
    "print(\"Best solution:\\n\", best_sol)\n",
    "plot_tour(cities, best_sol.visited)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "ScYBPTlsg2jx"
   },
   "outputs": [],
   "source": [
    "df.to_csv(\"base_train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Instances: 100%|███████████████████████████████████████████████████████████████| 50/50 [00:00<00:00, 9805.73instance/s]\n",
      "Solving Instances:   0%|                                                                  | 0/50 [00:00<?, ?instance/s]C:\\Users\\krr\\AppData\\Local\\Temp\\ipykernel_67940\\2783085547.py:15: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  eval_df = pd.concat([eval_df, pd.DataFrame([{\n",
      "Solving Instances: 100%|█████████████████████████████████████████████████████████| 50/50 [00:02<00:00, 23.18instance/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "nb_eval = 50\n",
    "fold = 10\n",
    "eval_df = pd.DataFrame(columns=[\"model_name\", \"cost\"])\n",
    "instances = [\n",
    "                TSP_Instance(np.random.rand(50, 2)) for _ in tqdm(\n",
    "                    range(nb_eval), desc=\"Instances\", unit=\"instance\", position=0, leave=True\n",
    "                )\n",
    "            ]\n",
    "greedy = SingleAgentSolver(env, GreedyAgent(ModelEvalActions(model)))\n",
    "solutions = []\n",
    "\n",
    "for instance in tqdm(instances, desc=\"Solving Instances\", unit=\"instance\", position=0, leave=True):\n",
    "    solution, *_ = greedy.solve(TSP_State(instance, visited=[0]))\n",
    "    eval_df = pd.concat([eval_df, pd.DataFrame([{\n",
    "        \"model_name\" : type(model).__name__,\n",
    "        \"cost\": solution.cost,                \n",
    "}]) ])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_name</th>\n",
       "      <th>cost</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CustomModel</td>\n",
       "      <td>6.446413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CustomModel</td>\n",
       "      <td>6.190472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CustomModel</td>\n",
       "      <td>6.771071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CustomModel</td>\n",
       "      <td>6.099047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CustomModel</td>\n",
       "      <td>6.905586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>CustomModel</td>\n",
       "      <td>6.519913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>CustomModel</td>\n",
       "      <td>6.386367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>CustomModel</td>\n",
       "      <td>6.025633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>CustomModel</td>\n",
       "      <td>6.611734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>CustomModel</td>\n",
       "      <td>6.911208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>CustomModel</td>\n",
       "      <td>7.819351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>CustomModel</td>\n",
       "      <td>6.874661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>CustomModel</td>\n",
       "      <td>6.913413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>CustomModel</td>\n",
       "      <td>6.312429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>CustomModel</td>\n",
       "      <td>6.052837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>CustomModel</td>\n",
       "      <td>5.901943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>CustomModel</td>\n",
       "      <td>7.193242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>CustomModel</td>\n",
       "      <td>6.139305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>CustomModel</td>\n",
       "      <td>6.076701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>CustomModel</td>\n",
       "      <td>6.181084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>CustomModel</td>\n",
       "      <td>7.038700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>CustomModel</td>\n",
       "      <td>6.484599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>CustomModel</td>\n",
       "      <td>5.956849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>CustomModel</td>\n",
       "      <td>6.838564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>CustomModel</td>\n",
       "      <td>6.775213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>CustomModel</td>\n",
       "      <td>6.264177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>CustomModel</td>\n",
       "      <td>6.905262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>CustomModel</td>\n",
       "      <td>6.707328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>CustomModel</td>\n",
       "      <td>6.703378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>CustomModel</td>\n",
       "      <td>6.400716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>CustomModel</td>\n",
       "      <td>6.968786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>CustomModel</td>\n",
       "      <td>6.011454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>CustomModel</td>\n",
       "      <td>6.580919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>CustomModel</td>\n",
       "      <td>7.079964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>CustomModel</td>\n",
       "      <td>6.966433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>CustomModel</td>\n",
       "      <td>6.969834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>CustomModel</td>\n",
       "      <td>5.476482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>CustomModel</td>\n",
       "      <td>6.631318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>CustomModel</td>\n",
       "      <td>6.447364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>CustomModel</td>\n",
       "      <td>6.121605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>CustomModel</td>\n",
       "      <td>6.893582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>CustomModel</td>\n",
       "      <td>6.690288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>CustomModel</td>\n",
       "      <td>5.984804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>CustomModel</td>\n",
       "      <td>6.780798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>CustomModel</td>\n",
       "      <td>6.131248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>CustomModel</td>\n",
       "      <td>5.854813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>CustomModel</td>\n",
       "      <td>6.596512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>CustomModel</td>\n",
       "      <td>6.546448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>CustomModel</td>\n",
       "      <td>6.061584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>CustomModel</td>\n",
       "      <td>6.463630</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     model_name      cost\n",
       "0   CustomModel  6.446413\n",
       "1   CustomModel  6.190472\n",
       "2   CustomModel  6.771071\n",
       "3   CustomModel  6.099047\n",
       "4   CustomModel  6.905586\n",
       "5   CustomModel  6.519913\n",
       "6   CustomModel  6.386367\n",
       "7   CustomModel  6.025633\n",
       "8   CustomModel  6.611734\n",
       "9   CustomModel  6.911208\n",
       "10  CustomModel  7.819351\n",
       "11  CustomModel  6.874661\n",
       "12  CustomModel  6.913413\n",
       "13  CustomModel  6.312429\n",
       "14  CustomModel  6.052837\n",
       "15  CustomModel  5.901943\n",
       "16  CustomModel  7.193242\n",
       "17  CustomModel  6.139305\n",
       "18  CustomModel  6.076701\n",
       "19  CustomModel  6.181084\n",
       "20  CustomModel  7.038700\n",
       "21  CustomModel  6.484599\n",
       "22  CustomModel  5.956849\n",
       "23  CustomModel  6.838564\n",
       "24  CustomModel  6.775213\n",
       "25  CustomModel  6.264177\n",
       "26  CustomModel  6.905262\n",
       "27  CustomModel  6.707328\n",
       "28  CustomModel  6.703378\n",
       "29  CustomModel  6.400716\n",
       "30  CustomModel  6.968786\n",
       "31  CustomModel  6.011454\n",
       "32  CustomModel  6.580919\n",
       "33  CustomModel  7.079964\n",
       "34  CustomModel  6.966433\n",
       "35  CustomModel  6.969834\n",
       "36  CustomModel  5.476482\n",
       "37  CustomModel  6.631318\n",
       "38  CustomModel  6.447364\n",
       "39  CustomModel  6.121605\n",
       "40  CustomModel  6.893582\n",
       "41  CustomModel  6.690288\n",
       "42  CustomModel  5.984804\n",
       "43  CustomModel  6.780798\n",
       "44  CustomModel  6.131248\n",
       "45  CustomModel  5.854813\n",
       "46  CustomModel  6.596512\n",
       "47  CustomModel  6.546448\n",
       "48  CustomModel  6.061584\n",
       "49  CustomModel  6.463630"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_df.reset_index().drop('index', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
